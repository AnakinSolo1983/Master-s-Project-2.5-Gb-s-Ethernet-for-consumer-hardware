From 319061a621e02a87f43e7a4d5d05f9328bab5437 Mon Sep 17 00:00:00 2001
From: Konstantin Ananyev <konstantin.ananyev@huawei.com>
Date: Mon, 7 Jul 2025 18:40:51 +0100
Subject: [PATCH] acl: support BPF(XDP) WIP(2)

What is done:
=============

In userspace creates BPF maps and populates them and can search through
them and produce correct result.
In kernel: written xdp program that can traverse these maps.

What is not done:
=================

Not clear how to make userspace and kernel to share the same map?
Should xdp be lodead first and then user-space just find map by name and
populate it?
Not tested in kernel space.
In kernel not supported multiple tries.

how to build
+++++++++++++

git clone -v  http://dpdk.org/git/dpdk dpdk-acl-bpf
cd dpdk-acl-bpf
git am -3 <this-patch-name>

meson setup --prefix=${PWD}/x86_64-default-linuxapp-gcc-dbg-install --werror -Dbuildtype=debug -Dc_args=-DRTE_ENABLE_ASSERT -Dmachine=default x86_64-default-linuxapp-gcc-dbg 2>&1 | tee bld-gcc-out1

ninja -v -j 8 -C x86_64-default-linuxapp-gcc-dbg/ 2>&1 | tee bld-gcc-out2

Userspace part
++++++++++++++

sudo /x86_64-default-linuxapp-gcc-dbg/app/dpdk-test-acl -n 12 --lcores='120' --no-pci --no-huge --log-level "debug" -- --rulesf=./dts/dep/test-acl-input/acl1v4_10k_rule --tracef=./dts/dep/test-acl-input/acl1v4_10k_trace --tracestep=1 --iter=1 --verbose=3 --rulenum=100000 --bpf

XPD part
++++++++

clang -O2 -g -Wall -target bpf -I./lib/acl/ -I./ -c app/test-acl/xdp_acl2.c -o app/test-acl/xdp_acl2.o

sudo ip netns exec ns1 xdp-loader load -vv eth5 /home/kananyev/dpdk-acl-bpf/app/test-acl/xdp_acl2.o
sudo ip netns exec ns1 xdp-loader status -vv
sudo ip netns exec ns1 bpftool map show
sudo ip netns exec ns1 xdp-loader unload -a -vv eth5

Signed-off-by: Konstantin Ananyev <konstantin.ananyev@huawei.com>
---
 app/test-acl/main.c      |  58 +++++++-
 app/test-acl/xdp_acl1.c  | 208 ++++++++++++++++++++++++++
 app/test-acl/xdp_acl2.c  | 288 ++++++++++++++++++++++++++++++++++++
 app/test-acl/xdp_prog1.c |  39 +++++
 lib/acl/acl_bpf.c        | 309 +++++++++++++++++++++++++++++++++++++++
 lib/acl/acl_bpf.h        |  36 +++++
 lib/acl/meson.build      |  15 ++
 lib/acl/rte_acl.h        |  21 +++
 8 files changed, 971 insertions(+), 3 deletions(-)
 create mode 100644 app/test-acl/xdp_acl1.c
 create mode 100644 app/test-acl/xdp_acl2.c
 create mode 100644 app/test-acl/xdp_prog1.c
 create mode 100644 lib/acl/acl_bpf.c
 create mode 100644 lib/acl/acl_bpf.h

diff --git a/app/test-acl/main.c b/app/test-acl/main.c
index 3a791b3ccf..a7dac8059d 100644
--- a/app/test-acl/main.c
+++ b/app/test-acl/main.c
@@ -6,6 +6,7 @@
 #include <rte_acl.h>
 #include <getopt.h>
 #include <string.h>
+#include <unistd.h>
 
 #include <rte_cycles.h>
 #include <rte_per_lcore.h>
@@ -41,6 +42,7 @@
 #define	OPT_ITER_NUM		"iter"
 #define	OPT_VERBOSE		"verbose"
 #define	OPT_IPV6		"ipv6"
+#define	OPT_BPF			"bpf"
 
 #define	TRACE_DEFAULT_NUM	0x10000
 #define	TRACE_STEP_MAX		0x1000
@@ -117,6 +119,8 @@ static struct {
 	uint32_t            used_traces;
 	void               *traces;
 	struct rte_acl_ctx *acx;
+	bool use_bpf;
+	struct rte_acl_bpf bpx;
 } config = {
 	.bld_categories = 3,
 	.run_categories = 1,
@@ -130,6 +134,7 @@ static struct {
 		.alg = RTE_ACL_CLASSIFY_DEFAULT,
 	},
 	.ipv6 = IPV6_FRMT_NONE,
+	.use_bpf = false,
 };
 
 static struct rte_acl_param prm = {
@@ -955,6 +960,34 @@ add_cb_rules(FILE *f, struct rte_acl_ctx *ctx)
 	return 0;
 }
 
+static void
+print_acl_bpf_ctx(const struct rte_acl_bpf *bpx)
+{
+	printf("acl_bpf={\n");
+	printf("\tctx_fd=%d,\n", bpx->ctx_fd);
+	printf("\ttrans_fd=%d,\n", bpx->trans_fd);
+	printf("}\n");
+
+#if 0
+	printf("bpf_ctx={\n");
+	printf("\tnum_trans=%u,\n", bcx->num_trans);
+	printf("\tmatch_index=%u,\n", bcx->match_index);
+	printf("\tnum_matches=%u,\n", bcx->num_matches);
+	printf("\tnum_tries=%u,\n", bcx->num_tries);
+	for (i = 0; i != bcx->num_tries; i++) {
+		printf("\ttrie[%u]={\n", i);
+		printf("\t\troot_index=%u,\n", bcx->trie[i].root_index);
+		printf("\t\tnum_offset=%u,\n", bcx->trie[i].num_offset);
+		printf("\t\tdata_offset={\n\t\t\t");
+		for (j = 0; j != bcx->trie[i].num_offset; j++)
+			printf(" %u,", bcx->trie[i].data_offset[j]); 
+		printf("\n\t\t},\n");
+		printf("\t},\n");
+	};
+	printf("}\n");
+#endif
+}
+
 static void
 acx_init(void)
 {
@@ -1015,6 +1048,11 @@ acx_init(void)
 
 	rte_acl_dump(config.acx);
 
+	if (ret == 0 && config.use_bpf == true) {
+		ret = rte_acl_bpf_init(&config.bpx, config.acx);
+		print_acl_bpf_ctx(&config.bpx);
+	}
+
 	if (ret != 0)
 		rte_exit(ret, "failed to build search context\n");
 }
@@ -1037,8 +1075,15 @@ search_ip5tuples_once(uint32_t categories, uint32_t step, const char *alg)
 			v += config.trace_sz;
 		}
 
-		ret = rte_acl_classify(config.acx, data, results,
-			n, categories);
+		if (config.use_bpf == false)
+			ret = rte_acl_classify(config.acx, data, results,
+				n, categories);
+		else {
+			ret = 0;
+			for (j = 0; j != n && ret == 0; j++)
+				ret = rte_acl_bpf_classify(&config.bpx, data[j],
+					config.trace_sz, results + j);
+		}
 
 		if (ret != 0)
 			rte_exit(ret, "classify for ipv%c_5tuples returns %d\n",
@@ -1194,7 +1239,8 @@ print_usage(const char *prgname)
 		"[--" OPT_ITER_NUM "=<number of iterations to perform>]\n"
 		"[--" OPT_VERBOSE "=<verbose level>]\n"
 		"[--" OPT_SEARCH_ALG "=%s]\n"
-		"[--" OPT_IPV6 "(=4B | 8B) <IPv6 rules and trace files>]\n",
+		"[--" OPT_IPV6 "(=4B | 8B) <IPv6 rules and trace files>]\n"
+		"[--" OPT_BPF "<enable bpf classify>]\n",
 		prgname, RTE_ACL_RESULTS_MULTIPLIER,
 		(uint32_t)RTE_ACL_MAX_CATEGORIES,
 		buf);
@@ -1217,6 +1263,7 @@ dump_config(FILE *f)
 	fprintf(f, "%s:%u(%s)\n", OPT_SEARCH_ALG, config.alg.alg,
 		config.alg.name);
 	fprintf(f, "%s:%u\n", OPT_IPV6, config.ipv6);
+	fprintf(f, "%s:%d\n", OPT_BPF, config.use_bpf);
 }
 
 static void
@@ -1246,6 +1293,7 @@ get_input_opts(int argc, char **argv)
 		{OPT_VERBOSE, 1, 0, 0},
 		{OPT_SEARCH_ALG, 1, 0, 0},
 		{OPT_IPV6, 2, 0, 0},
+		{OPT_BPF, 0, 0, 0},
 		{NULL, 0, 0, 0}
 	};
 
@@ -1297,6 +1345,8 @@ get_input_opts(int argc, char **argv)
 			config.ipv6 = IPV6_FRMT_U32;
 			if (optarg != NULL)
 				get_ipv6_opt(optarg, lgopts[opt_idx].name);
+		} else if (strcmp(lgopts[opt_idx].name, OPT_BPF) == 0) {
+			config.use_bpf = true;
 		}
 	}
 	config.trace_sz = config.ipv6 ? sizeof(struct ipv6_5tuple) :
@@ -1335,6 +1385,8 @@ main(int argc, char **argv)
 
 	rte_eal_mp_wait_lcore();
 
+	if (config.use_bpf)
+		rte_acl_bpf_fini(&config.bpx);
 	rte_acl_free(config.acx);
 	return 0;
 }
diff --git a/app/test-acl/xdp_acl1.c b/app/test-acl/xdp_acl1.c
new file mode 100644
index 0000000000..567a835707
--- /dev/null
+++ b/app/test-acl/xdp_acl1.c
@@ -0,0 +1,208 @@
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/udp.h>
+#include <linux/tcp.h>
+
+#include <limits.h>
+#include <stdint.h>
+#include "acl_bpf.h"
+
+/*
+ * !!! copy of all defines - to remove
+ */
+
+/** Mask value of type "tp" for the first "ln" bit set. */
+#define RTE_LEN2MASK(ln, tp)    \
+	((tp)((uint64_t)-1 >> (sizeof(uint64_t) * CHAR_BIT - (ln))))
+
+enum {
+        RTE_ACL_TYPE_SHIFT = 29,
+        RTE_ACL_MAX_INDEX = RTE_LEN2MASK(RTE_ACL_TYPE_SHIFT, uint32_t),
+        RTE_ACL_MAX_PRIORITY = RTE_ACL_MAX_INDEX,
+        RTE_ACL_MIN_PRIORITY = 1,
+};
+
+#define RTE_ACL_NODE_DFA	(0 << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_SINGLE	(1U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_QRANGE	(3U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_MATCH	(4U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_TYPE	(7U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_UNDEFINED	UINT32_MAX
+
+#define RTE_ACL_QUAD_MAX	5
+#define RTE_ACL_QUAD_SIZE	4
+#define RTE_ACL_QUAD_SINGLE	UINT64_C(0x7f7f7f7f00000000)
+
+#define RTE_ACL_SINGLE_TRIE_SIZE	2000
+
+#define RTE_ACL_DFA_MAX		UINT8_MAX
+#define RTE_ACL_DFA_SIZE	(UINT8_MAX + 1)
+
+#define RTE_ACL_DFA_GR64_SIZE	64
+#define RTE_ACL_DFA_GR64_NUM	(RTE_ACL_DFA_SIZE / RTE_ACL_DFA_GR64_SIZE)
+#define RTE_ACL_DFA_GR64_BIT	\
+	(CHAR_BIT * sizeof(uint32_t) / RTE_ACL_DFA_GR64_NUM)
+
+#define RTE_ACL_NODE_INDEX	((uint32_t)~RTE_ACL_NODE_TYPE)
+
+#define SCALAR_QRANGE_MULT	0x01010101
+#define SCALAR_QRANGE_MASK	0x7f7f7f7f
+#define SCALAR_QRANGE_MIN	0x80808080
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, struct rte_acl_bpf_ctx);
+        __uint(max_entries, 1);
+} acl_ctx SEC(".maps");
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, uint64_t);
+        __uint(max_entries, 0x4000);
+} acl_trans SEC(".maps");
+
+struct packet_field {
+	uint8_t proto;
+	uint32_t src_ip;
+	uint32_t dst_ip;
+	uint16_t src_port;
+	uint16_t dst_port;
+};
+
+union packet_data {
+	struct packet_field data;
+	uint8_t raw[sizeof(struct packet_field)];
+};
+
+const uint32_t data_ofs[] = {
+	offsetof(struct packet_field, proto),
+	offsetof(struct packet_field, src_ip),
+	offsetof(struct packet_field, src_ip) + 1,
+	offsetof(struct packet_field, src_ip) + 2,
+	offsetof(struct packet_field, src_ip) + 3,
+	offsetof(struct packet_field, dst_ip),
+	offsetof(struct packet_field, dst_ip) + 1,
+	offsetof(struct packet_field, dst_ip) + 2,
+	offsetof(struct packet_field, dst_ip) + 3,
+	offsetof(struct packet_field, src_port),
+	offsetof(struct packet_field, src_port) + 1,
+	offsetof(struct packet_field, dst_port),
+	offsetof(struct packet_field, dst_port) + 1,
+};
+
+#define DIM(a)	(sizeof(a) / sizeof(a[0]))
+
+static inline uint32_t
+scan_forward(uint32_t input, uint32_t max)
+{
+	return (input == 0) ? max : __builtin_ctz(input);
+}
+
+static uint32_t
+resolve_next_index(uint64_t transition, uint8_t input)
+{
+	uint32_t addr, index, ranges, x, a, b, c;
+
+	/* break transition into component parts */
+	ranges = transition >> (sizeof(index) * CHAR_BIT);
+	index = transition & ~RTE_ACL_NODE_INDEX;
+	addr = transition ^ index;
+
+	if (index != RTE_ACL_NODE_DFA) {
+		/* calc address for a QRANGE/SINGLE node */
+		c = (uint32_t)input * SCALAR_QRANGE_MULT;
+		a = ranges | SCALAR_QRANGE_MIN;
+		a -= (c & SCALAR_QRANGE_MASK);
+		b = c & SCALAR_QRANGE_MIN;
+		a &= SCALAR_QRANGE_MIN;
+		a ^= (ranges ^ b) & (a ^ b);
+		x = scan_forward(a, 32) >> 3;
+	} else {
+		/* calc address for a DFA node */
+		x = ranges >> (input /
+			RTE_ACL_DFA_GR64_SIZE * RTE_ACL_DFA_GR64_BIT);
+		x &= UINT8_MAX;
+		x = input - x;
+	}
+
+	addr += x;
+	return addr;
+}
+
+
+SEC("xdp_prog")
+int xdp_acl_prog1(struct xdp_md *ctx)
+{
+	void *data_end;
+	void *data;
+	uint32_t i, idx, input, iphlen;
+	uint64_t trans;
+	const uint64_t *val;
+	struct ethhdr *eth;
+	struct iphdr *iph;
+	struct udphdr *udph;
+	union packet_data pd;
+	const struct rte_acl_bpf_ctx *bcx;
+
+	data_end = (void *)(long)ctx->data_end;
+	data = (void *)(long)ctx->data;
+
+	eth = data;
+	if (data + sizeof(*eth) > data_end)
+        	return XDP_DROP;
+
+	if (eth->h_proto != htons(ETH_P_IP))
+		return XDP_PASS;
+
+	iph = (struct iphdr *)(eth + 1);
+	if ((void *)(iph + 1) > data_end)
+		return XDP_DROP;
+
+	pd.data.proto = iph->protocol;
+	pd.data.src_ip = iph->saddr;
+	pd.data.dst_ip = iph->daddr;
+
+	iphlen = iph->ihl * sizeof(uint32_t);
+	udph = (struct udphdr *)((uint8_t *)iph + iphlen);
+
+	if((void *)(udph + 1) > data_end)
+		return XDP_PASS;
+
+	pd.data.src_port = udph->source;
+	pd.data.dst_port = udph->dest;
+
+	i = 0;
+	bcx = bpf_map_lookup_elem(&acl_ctx, &i);
+	if (bcx == NULL)
+		return XDP_PASS;
+
+	for (i = 0; i != DIM(data_ofs); i++) {
+		
+		input = pd.raw[data_ofs[i]];
+		if (i == 0)
+			idx = bcx->trie[0].root_index + input;
+		else
+			idx = resolve_next_index(trans, input);
+
+		val = bpf_map_lookup_elem(&acl_trans, &idx);
+		if (val == NULL)
+			return XDP_PASS;
+
+		trans = *val;
+
+		/* if match is found */
+		if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+			break;
+		}
+	}
+
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/app/test-acl/xdp_acl2.c b/app/test-acl/xdp_acl2.c
new file mode 100644
index 0000000000..c22966b01c
--- /dev/null
+++ b/app/test-acl/xdp_acl2.c
@@ -0,0 +1,288 @@
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/udp.h>
+#include <linux/tcp.h>
+
+#include <limits.h>
+#include <stdint.h>
+#include "acl_bpf.h"
+
+/*
+ * !!! copy of all defines - to remove
+ */
+
+/** Mask value of type "tp" for the first "ln" bit set. */
+#define RTE_LEN2MASK(ln, tp)    \
+	((tp)((uint64_t)-1 >> (sizeof(uint64_t) * CHAR_BIT - (ln))))
+
+enum {
+        RTE_ACL_TYPE_SHIFT = 29,
+        RTE_ACL_MAX_INDEX = RTE_LEN2MASK(RTE_ACL_TYPE_SHIFT, uint32_t),
+        RTE_ACL_MAX_PRIORITY = RTE_ACL_MAX_INDEX,
+        RTE_ACL_MIN_PRIORITY = 1,
+};
+
+#define RTE_ACL_NODE_DFA	(0 << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_SINGLE	(1U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_QRANGE	(3U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_MATCH	(4U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_TYPE	(7U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_UNDEFINED	UINT32_MAX
+
+#define RTE_ACL_QUAD_MAX	5
+#define RTE_ACL_QUAD_SIZE	4
+#define RTE_ACL_QUAD_SINGLE	UINT64_C(0x7f7f7f7f00000000)
+
+#define RTE_ACL_SINGLE_TRIE_SIZE	2000
+
+#define RTE_ACL_DFA_MAX		UINT8_MAX
+#define RTE_ACL_DFA_SIZE	(UINT8_MAX + 1)
+
+#define RTE_ACL_DFA_GR64_SIZE	64
+#define RTE_ACL_DFA_GR64_NUM	(RTE_ACL_DFA_SIZE / RTE_ACL_DFA_GR64_SIZE)
+#define RTE_ACL_DFA_GR64_BIT	\
+	(CHAR_BIT * sizeof(uint32_t) / RTE_ACL_DFA_GR64_NUM)
+
+#define RTE_ACL_NODE_INDEX	((uint32_t)~RTE_ACL_NODE_TYPE)
+
+#define SCALAR_QRANGE_MULT	0x01010101
+#define SCALAR_QRANGE_MASK	0x7f7f7f7f
+#define SCALAR_QRANGE_MIN	0x80808080
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, struct rte_acl_bpf_ctx);
+        __uint(max_entries, 1);
+} acl_ctx SEC(".maps");
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, uint64_t);
+        __uint(max_entries, 0x400000);
+} acl_trans SEC(".maps");
+
+struct packet_field {
+	uint8_t proto;
+	uint32_t src_ip;
+	uint32_t dst_ip;
+	uint16_t src_port;
+	uint16_t dst_port;
+};
+
+union packet_data {
+	struct packet_field data;
+	uint8_t raw[sizeof(struct packet_field)];
+};
+
+const uint32_t data_ofs[] = {
+	offsetof(struct packet_field, proto),
+	offsetof(struct packet_field, src_ip),
+	offsetof(struct packet_field, src_ip) + 1,
+	offsetof(struct packet_field, src_ip) + 2,
+	offsetof(struct packet_field, src_ip) + 3,
+	offsetof(struct packet_field, dst_ip),
+	offsetof(struct packet_field, dst_ip) + 1,
+	offsetof(struct packet_field, dst_ip) + 2,
+	offsetof(struct packet_field, dst_ip) + 3,
+	offsetof(struct packet_field, src_port),
+	offsetof(struct packet_field, src_port) + 1,
+	offsetof(struct packet_field, dst_port),
+	offsetof(struct packet_field, dst_port) + 1,
+};
+
+#define DIM(a)	(sizeof(a) / sizeof(a[0]))
+
+static void *
+resolve_match(uint32_t match_index, uint64_t trans)
+{
+	uint32_t idx;
+
+	trans &= RTE_ACL_NODE_INDEX;
+	idx = match_index + trans;
+
+	/* get match record */
+	return bpf_map_lookup_elem(&acl_trans, &idx);
+}
+
+static inline uint32_t
+scan_forward(uint32_t input, uint32_t max)
+{
+	return (input == 0) ? max : __builtin_ctz(input);
+}
+
+static uint32_t
+resolve_next_index(uint64_t transition, uint8_t input)
+{
+	uint32_t addr, index, ranges, x, a, b, c;
+
+	/* break transition into component parts */
+	ranges = transition >> (sizeof(index) * CHAR_BIT);
+	index = transition & ~RTE_ACL_NODE_INDEX;
+	addr = transition ^ index;
+
+	if (index != RTE_ACL_NODE_DFA) {
+		/* calc address for a QRANGE/SINGLE node */
+		c = (uint32_t)input * SCALAR_QRANGE_MULT;
+		a = ranges | SCALAR_QRANGE_MIN;
+		a -= (c & SCALAR_QRANGE_MASK);
+		b = c & SCALAR_QRANGE_MIN;
+		a &= SCALAR_QRANGE_MIN;
+		a ^= (ranges ^ b) & (a ^ b);
+		x = scan_forward(a, 32) >> 3;
+	} else {
+		/* calc address for a DFA node */
+		x = ranges >> (input /
+			RTE_ACL_DFA_GR64_SIZE * RTE_ACL_DFA_GR64_BIT);
+		x &= UINT8_MAX;
+		x = input - x;
+	}
+
+	addr += x;
+	return addr;
+}
+
+static inline int
+one_step_trans(uint32_t match_index, uint8_t input, uint64_t trans,
+	uint64_t *next) 
+{
+	uint32_t idx;
+	const uint64_t *val;
+
+	idx = resolve_next_index(trans, input);
+	val = bpf_map_lookup_elem(&acl_trans, &idx);
+	if (val == NULL)
+		return XDP_PASS;
+	trans = *val;
+	/* if match is found */
+	if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+		val = resolve_match(match_index, trans);
+		if (val == NULL)
+			return XDP_PASS;
+		return XDP_DROP;
+	}
+	*next = trans;
+	return XDP_ABORTED;
+}
+
+
+SEC("xdp_prog")
+int xdp_acl_prog1(struct xdp_md *ctx)
+{
+	void *data_end;
+	void *data;
+	int32_t rc;
+	uint32_t i, idx, input, iphlen, match_index;
+	uint64_t trans;
+	const uint64_t *val;
+	struct ethhdr *eth;
+	struct iphdr *iph;
+	struct udphdr *udph;
+	union packet_data pd;
+	const struct rte_acl_bpf_ctx *bcx;
+
+	data_end = (void *)(long)ctx->data_end;
+	data = (void *)(long)ctx->data;
+
+	eth = data;
+	if (data + sizeof(*eth) > data_end)
+        	return XDP_DROP;
+
+	if (eth->h_proto != htons(ETH_P_IP))
+		return XDP_PASS;
+
+	iph = (struct iphdr *)(eth + 1);
+	if ((void *)(iph + 1) > data_end)
+		return XDP_DROP;
+
+	pd.data.proto = iph->protocol;
+	pd.data.src_ip = iph->saddr;
+	pd.data.dst_ip = iph->daddr;
+
+	iphlen = iph->ihl * sizeof(uint32_t);
+	udph = (struct udphdr *)((uint8_t *)iph + iphlen);
+
+	if((void *)(udph + 1) > data_end)
+		return XDP_PASS;
+
+	pd.data.src_port = udph->source;
+	pd.data.dst_port = udph->dest;
+
+	i = 0;
+	bcx = bpf_map_lookup_elem(&acl_ctx, &i);
+	if (bcx == NULL)
+		return XDP_PASS;
+
+	match_index = bcx->match_index;
+
+	input = pd.data.proto;
+	idx = bcx->trie[0].root_index + input;
+	val = bpf_map_lookup_elem(&acl_trans, &idx);
+	if (val == NULL)
+		return XDP_PASS;
+	trans = *val;
+	/* if match is found */
+	if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+		val = resolve_match(match_index, trans);
+		if (val == NULL)
+			return XDP_PASS;
+		return XDP_DROP;
+	}
+
+	rc = one_step_trans(match_index, pd.raw[4], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[5], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[6], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[7], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[8], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[9], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[10], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[11], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[12], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[13], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[14], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[15], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/app/test-acl/xdp_prog1.c b/app/test-acl/xdp_prog1.c
new file mode 100644
index 0000000000..d192a425a9
--- /dev/null
+++ b/app/test-acl/xdp_prog1.c
@@ -0,0 +1,39 @@
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+
+struct {
+        __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+        __type(key, uint32_t);
+        __type(value, uint64_t);
+        __uint(max_entries, 1);
+} rxcnt SEC(".maps");
+
+
+SEC("xdp_prog")
+int xdp_prog1(struct xdp_md *ctx)
+{
+	void *data_end = (void *)(long)ctx->data_end;
+	void *data = (void *)(long)ctx->data;
+	struct ethhdr *eth = data;
+	uint16_t h_proto;
+	uint32_t key;
+	uint64_t *val;
+
+	if (data + sizeof(struct ethhdr) > data_end)
+        	return XDP_DROP;
+
+	h_proto = eth->h_proto;
+
+	if (h_proto == htons(ETH_P_IPV6)) {
+		key = 0;
+		val = bpf_map_lookup_elem(&rxcnt, &key);
+		if (val != NULL)
+			*val += 1;
+	}
+
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/lib/acl/acl_bpf.c b/lib/acl/acl_bpf.c
new file mode 100644
index 0000000000..43bf5e8b19
--- /dev/null
+++ b/lib/acl/acl_bpf.c
@@ -0,0 +1,309 @@
+/* SPDX-License-Identifier: BSD-3-Clause
+ * Copyright(c) 2010-2014 Intel Corporation
+ */
+
+#include <rte_acl.h>
+#include "acl.h"
+#include "acl_log.h"
+#include "acl_run.h"
+#include "acl_bpf.h"
+
+#include <bpf/bpf.h>
+#include <unistd.h>
+
+static void
+acl_bpf_reset(struct rte_acl_bpf *btx)
+{
+	btx->trans_fd = -1;
+	btx->ctx_fd = -1;
+}
+
+static void
+fill_bpf_ctx(struct rte_acl_bpf_ctx *btx, const struct rte_acl_ctx *ctx)
+{
+	uint32_t i, j, k, n;
+
+	memset(btx, 0, sizeof(*btx));
+
+	n = ctx->match_index + ctx->num_rules + 1;
+	btx->num_trans = n;
+	btx->match_index = ctx->match_index;
+	btx->num_matches = ctx->num_rules + 1;
+
+	/* copy tries */
+	btx->num_tries = ctx->num_tries;
+	for (i = 0; i != btx->num_tries; i++) {
+		btx->trie[i].root_index = ctx->trie[i].root_index;
+		n = 4 * (ctx->trie[i].num_data_indexes - 1) + 1;
+		btx->trie[i].num_offset = n;
+		btx->trie[i].data_offset[0] = ctx->trie[i].data_index[0];
+		for (j = 1; j != ctx->trie[i].num_data_indexes; j++) {
+			k = 4 * (j - 1) + 1;
+			n = ctx->trie[i].data_index[j];
+			btx->trie[i].data_offset[k] = n;
+			btx->trie[i].data_offset[k + 1] = n + 1;
+			btx->trie[i].data_offset[k + 2] = n + 2;
+			btx->trie[i].data_offset[k + 3] = n + 3;
+		}
+	}
+}
+
+int
+rte_acl_bpf_init(struct rte_acl_bpf *bpx, const struct rte_acl_ctx *ctx)
+{
+	uint32_t i, j, k;
+	int32_t rc;
+	struct rte_acl_bpf_ctx btx;
+	union rte_acl_bpf_match bpf_match;
+	const struct rte_acl_match_results *match;
+	char buf[0x100];
+
+	if (bpx == NULL || ctx == NULL)
+		return -EINVAL;
+
+	acl_bpf_reset(bpx);
+	fill_bpf_ctx(&btx, ctx);
+
+	/* create CTX map */
+	snprintf(buf, sizeof(buf), "%s_ctx", ctx->name);
+	bpx->ctx_fd = bpf_map_create(BPF_MAP_TYPE_ARRAY, buf,
+		sizeof(uint32_t), sizeof(btx), 1, NULL);
+	rc = (bpx->ctx_fd < 0) ? -errno : 0;
+	printf("%s:%d  "
+		"bpf_map_create(name=\"%s\", sz=%u) returns %d, errno=%d\n",
+		__func__, __LINE__, buf, 1, bpx->ctx_fd, rc);
+	if (rc != 0) {
+		rte_acl_bpf_fini(bpx);
+		return rc;
+	}
+
+	/* fill CTX map */
+	i = 0;
+	rc = bpf_map_update_elem(bpx->ctx_fd, &i, &btx, BPF_ANY);
+	if (rc != 0) {
+		printf("%s:%d  "
+			"bpf_map_update_elem(fd=%d, key=%u, val=%p"
+			" failed, rc=%d, errno=%d\n",
+			__func__, __LINE__,
+			bpx->ctx_fd, i, &btx, rc, errno);
+		rte_acl_bpf_fini(bpx);
+		return rc;
+	}
+
+	/* create TRANS map */
+	snprintf(buf, sizeof(buf), "%s_trans", ctx->name);
+	bpx->trans_fd = bpf_map_create(BPF_MAP_TYPE_ARRAY, buf,
+		sizeof(uint32_t), sizeof(uint64_t), btx.num_trans, NULL);
+	rc = (bpx->trans_fd < 0) ? -errno : 0;
+	printf("%s:%d  "
+		"bpf_map_create(name=\"%s\", sz=%u) returns %d, errno=%d\n",
+		__func__, __LINE__, buf, btx.num_trans, bpx->trans_fd, rc);
+	if (rc != 0) {
+		rte_acl_bpf_fini(bpx);
+		return rc;
+	}
+
+	/* fill TRANS map */
+	for (i = 0; i != btx.match_index && rc == 0; i++) {
+		rc = bpf_map_update_elem(bpx->trans_fd, &i,
+				ctx->trans_table + i, BPF_ANY);
+	}
+
+	match = ((const struct rte_acl_match_results *)(ctx->trans_table + i));
+	for(j = 0; j != btx.num_matches && rc == 0; j++) {
+		k = i + j;
+		bpf_match.result = match[j].results[0];
+		bpf_match.priority = match[j].priority[0];
+		rc = bpf_map_update_elem(bpx->trans_fd, &k, &bpf_match.raw,
+			BPF_ANY);
+	}
+
+	if (rc != 0) {
+		printf("%s:%d  "
+			"bpf_map_update_elem(fd=%d, key=%u, val=%" PRIx64
+			" failed, rc=%d, errno=%d\n",
+			__func__, __LINE__,
+			bpx->trans_fd, i, ctx->trans_table[i],
+			rc, errno);
+		rte_acl_bpf_fini(bpx);
+		return rc;
+	}
+
+	return 0;
+}
+
+void
+rte_acl_bpf_fini(struct rte_acl_bpf *bpx)
+{
+	close(bpx->trans_fd);
+	close(bpx->ctx_fd);
+	acl_bpf_reset(bpx);
+}
+
+static int
+resolve_match(int32_t fd, uint32_t match_index, uint64_t trans,
+	 union rte_acl_bpf_match *match)
+{
+	int32_t rc;
+	uint32_t idx;
+
+	trans &= RTE_ACL_NODE_INDEX;
+	idx = match_index + trans;
+
+	/* get match record */
+	rc = bpf_map_lookup_elem(fd, &idx, match);
+	if (rc != 0) {
+		printf("%s:%d  "
+			"bpf_map_lokup_elem(fd=%d, key=%u) failed, "
+			" rc=%d, errno=%d\n",
+			__func__, __LINE__, fd, idx, rc, errno);
+		return rc;
+	}
+
+	return 0;
+}
+
+static inline uint32_t
+scan_forward(uint32_t input, uint32_t max)
+{
+	return (input == 0) ? max : rte_bsf32(input);
+}
+
+static uint32_t
+resolve_next_index(uint64_t transition, uint8_t input)
+{
+	uint32_t addr, index, ranges, x, a, b, c;
+
+	/* break transition into component parts */
+	ranges = transition >> (sizeof(index) * CHAR_BIT);
+	index = transition & ~RTE_ACL_NODE_INDEX;
+	addr = transition ^ index;
+
+	if (index != RTE_ACL_NODE_DFA) {
+		/* calc address for a QRANGE/SINGLE node */
+		c = (uint32_t)input * SCALAR_QRANGE_MULT;
+		a = ranges | SCALAR_QRANGE_MIN;
+		a -= (c & SCALAR_QRANGE_MASK);
+		b = c & SCALAR_QRANGE_MIN;
+		a &= SCALAR_QRANGE_MIN;
+		a ^= (ranges ^ b) & (a ^ b);
+		x = scan_forward(a, 32) >> 3;
+	} else {
+		/* calc address for a DFA node */
+		x = ranges >> (input /
+			RTE_ACL_DFA_GR64_SIZE * RTE_ACL_DFA_GR64_BIT);
+		x &= UINT8_MAX;
+		x = input - x;
+	}
+
+	addr += x;
+	return addr;
+}
+
+static int
+acl_trie_search(const struct rte_acl_bpf_ctx *btx, uint32_t trie_idx,
+	int32_t trans_fd, const uint8_t *data, uint32_t data_len,
+	union rte_acl_bpf_match *match)
+{
+	int32_t rc;
+	uint32_t data_ofs, i, idx;
+	uint64_t trans;
+	uint8_t input;
+
+	if (btx->trie[trie_idx].data_offset[0] >= data_len)
+		return -ERANGE;
+
+	i = 0;
+	data_ofs = btx->trie[trie_idx].data_offset[i];
+	input = data[data_ofs];
+	idx = btx->trie[trie_idx].root_index + input;
+
+	do {
+
+		/* get next transision */
+		rc = bpf_map_lookup_elem(trans_fd, &idx, &trans);
+		if (rc != 0)
+			break;
+
+		/* if match is found */
+		if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+			rc = resolve_match(trans_fd, btx->match_index,
+				trans, match);
+			break;
+		}
+
+		/* read next data offset */
+		if (++i == btx->trie[trie_idx].num_offset)
+			break;
+
+		/* get next input byte */
+		data_ofs = btx->trie[trie_idx].data_offset[i];
+		if (data_ofs >= data_len) {
+			rc = -ERANGE;
+			break;
+		/* get next trans based on input */
+		} else {
+			input = data[data_ofs];
+			idx = resolve_next_index(trans, input);
+		}
+	} while (true);
+
+	if (rc != 0) {
+		printf("%s:%d  ERROR at transition lookup: "
+			"data_index=%u, data_offset=%u, data_value=%#hhx: "
+			"trans_fd=%d, key=%u failed, "
+			" rc=%d, errno=%d\n",
+			__func__, __LINE__,
+			i, data_ofs, input,
+			trans_fd, idx,
+			rc, errno);
+		return rc;
+	} else if (i == btx->trie[trie_idx].num_offset) {
+		printf("%s:%d(trans_fd=%d, data=%p, offset_idx=%u: "
+			"!!! NO MATCH WAS FOUND !!!",
+			__func__, __LINE__,  trans_fd, data, i);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+int
+rte_acl_bpf_classify(const struct rte_acl_bpf *bpx, const uint8_t *data,
+	uint32_t data_len, uint32_t *res)
+{
+	int32_t rc;
+	uint32_t i;
+	struct rte_acl_bpf_ctx btx;
+	union rte_acl_bpf_match cur, match;
+
+	if (bpx == NULL || data == NULL || data_len == 0 || res == 0)
+		return -EINVAL;
+
+	/* read CTX record */
+	i = 0;
+	rc = bpf_map_lookup_elem(bpx->ctx_fd, &i, &btx);
+	if (rc != 0) {
+		printf("%s:%d  "
+			"bpf_map_lokup_elem(fd=%d, key=%u) failed, "
+			" rc=%d, errno=%d\n",
+			__func__, __LINE__, bpx->ctx_fd, i, rc, errno);
+		return rc;
+	}
+
+	cur.priority = INT32_MIN;
+	cur.result = 0;
+	for (i = 0; i != btx.num_tries; i++) {
+		rc = acl_trie_search(&btx, i, bpx->trans_fd, data, data_len,
+			&match);
+		if (rc != 0)
+			return rc;	
+		/* if we found a match with greater priority, then use it */
+		if (match.priority >= cur.priority)
+			cur = match;
+	}
+
+	*res = cur.result;
+	return rc;
+}
+
diff --git a/lib/acl/acl_bpf.h b/lib/acl/acl_bpf.h
new file mode 100644
index 0000000000..75fe2d6722
--- /dev/null
+++ b/lib/acl/acl_bpf.h
@@ -0,0 +1,36 @@
+/* SPDX-License-Identifier: BSD-3-Clause
+ * Copyright(c) 2010-2014 Intel Corporation
+ */
+
+#ifndef _ACL_BPF_H_
+#define _ACL_BPF_H_
+
+/** MAX number of tries per one ACL BPF context.*/
+#define RTE_ACL_BPF_MAX_TRIES	8
+
+/** MAX bytes to classify for BPF */
+#define RTE_ACL_BPF_MAX_DATA_LEN	40
+
+struct rte_acl_bpf_trie {
+	uint32_t root_index;
+	uint32_t num_offset;
+	uint32_t data_offset[RTE_ACL_BPF_MAX_DATA_LEN];
+};
+
+struct rte_acl_bpf_ctx {
+	uint32_t num_trans;
+	uint32_t match_index;
+	uint32_t num_matches;
+	uint32_t num_tries;
+	struct rte_acl_bpf_trie trie[RTE_ACL_BPF_MAX_TRIES];
+};
+
+union rte_acl_bpf_match {
+	uint64_t raw;
+	struct {
+		uint32_t result;
+		int32_t priority;
+	};
+};
+
+#endif /* _ACL_BPF_H_ */
diff --git a/lib/acl/meson.build b/lib/acl/meson.build
index 87e9f25f8e..e61740a40e 100644
--- a/lib/acl/meson.build
+++ b/lib/acl/meson.build
@@ -26,3 +26,18 @@ elif dpdk_conf.has('RTE_ARCH_ARM')
 elif dpdk_conf.has('RTE_ARCH_PPC_64')
     sources += files('acl_run_altivec.c')
 endif
+
+bpf_dep = dependency('libbpf', required: false, method: 'pkg-config')
+if not bpf_dep.found()
+    bpf_dep = cc.find_library('bpf', required: false)
+endif
+
+if bpf_dep.found()
+    dpdk_conf.set('RTE_LIBRTE_ACL_BPF', 1)
+    sources += files('acl_bpf.c')
+    ext_deps += bpf_dep
+else
+    warning('libbpf is missing, rte_acl_ BPF API will be disabled')
+endif
+
+
diff --git a/lib/acl/rte_acl.h b/lib/acl/rte_acl.h
index 95354cabb8..ec6a499364 100644
--- a/lib/acl/rte_acl.h
+++ b/lib/acl/rte_acl.h
@@ -359,6 +359,27 @@ rte_acl_dump(const struct rte_acl_ctx *ctx);
 void
 rte_acl_list_dump(void);
 
+/**
+ * BPF related API
+ */
+
+struct rte_acl_bpf {
+	/** file desc for transition map */
+	int32_t trans_fd;
+	/** file desc for context map */
+	int32_t ctx_fd;
+};
+
+int
+rte_acl_bpf_init(struct rte_acl_bpf *bpx, const struct rte_acl_ctx *ctx);
+
+void
+rte_acl_bpf_fini(struct rte_acl_bpf *bpx);
+
+int
+rte_acl_bpf_classify(const struct rte_acl_bpf *bpx, const uint8_t *data,
+        uint32_t data_len, uint32_t *res);
+
 #ifdef __cplusplus
 }
 #endif
-- 
2.43.0

