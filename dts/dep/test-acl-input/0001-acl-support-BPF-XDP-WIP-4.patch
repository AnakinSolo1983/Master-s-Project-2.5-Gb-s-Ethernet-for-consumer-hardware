From a071adde2a77aa6bbc455ce5857311af9a7fa60d Mon Sep 17 00:00:00 2001
From: Konstantin Ananyev <konstantin.ananyev@huawei.com>
Date: Wed, 23 Jul 2025 23:34:37 +0100
Subject: [PATCH] acl: support BPF(XDP) WIP(4)

What changed:
=============

1) create new app to loaf/test BPF maps:
app/acl-bpf
2) Added third map that contains catual rules (that allows to view map entires and see 'hit' counters)
3) add warning into rte_acl_bmap_fill() when ACL CTX is too big and can't be properly used by XDP prog
   (num_tries > 1)
4) updated XDP prog to use 3 BPF maps ( app/acl-bpf/xdp_acl4.c)
5) updated acl-bpf userspace prog: to awaly do ACL search when trace-file is presenet

How it works:
============

clang -O2 -g -Wall -target bpf -I./lib/acl/ -I./ -c app/acl-bpf/xdp_acl4.c -o app/acl-bpf/xdp_acl4.o

ip netns exec ns1 xdp-loader load -vv eth5 /home/kananyev/dpdk-acl-bpf/app/acl-bpf/xdp_acl4.o

p netns exec ns1 bpftool map show
2: prog_array  name hid_jmp_table  flags 0x0
        key 4B  value 4B  max_entries 1024  memlock 8512B
        owner_prog_type tracing  owner jited
13: hash_of_maps  name cgroup_hash  flags 0x0
        key 8B  value 4B  max_entries 2048  memlock 191296B
        pids systemd(1), (sd-pam)(101701), (sd-pam)(101894)
1301: array  name acl_ctx  flags 0x0
        key 4B  value 1360B  max_entries 1  memlock 1680B
        btf_id 2014
1302: array  name acl_trans  flags 0x0
        key 4B  value 8B  max_entries 4194304  memlock 33554752B
        btf_id 2014
1303: array  name acl_rule  flags 0x0
        key 4B  value 48B  max_entries 65536  memlock 3146048B
        btf_id 2014
1304: array  name .rodata.cst32  flags 0x80
        key 4B  value 32B  max_entries 1  memlock 352B
        frozen
1306: array  name libbpf_global  flags 0x0
        key 4B  value 32B  max_entries 1  memlock 352B
1307: array  name pid_iter.rodata  flags 0x480
        key 4B  value 4B  max_entries 1  memlock 8192B
        btf_id 2023  frozen
        pids bpftool(104404)
1308: array  name libbpf_det_bind  flags 0x0
        key 4B  value 32B  max_entries 1  memlock 352B

stdbuf -o0 -e0 ./dpdk-acl-bpf/x86_64-default-linuxapp-gcc13-dbg/app/dpdk-acl-bpf -n 1 --lcores=0 --no-p
ci --no-huge --log-level "debug" -- --rulesf=./dts/dep/test-acl-input/acl1v4_10k_rule --iter=1 --verbose=3 --rulenum=100000 --tracenum=100000 --bpf="1301:1302:1303"

stdbuf -o0 -e0 ./dpdk-acl-bpf/x86_64-default-linuxapp-gcc13-dbg/app/dpdk-acl-bpf -n 12 --lcores='120' --no-pci --no-huge --log-level "debug" -- --rulesf=./dts/dep/test-acl-input/acl1v4_10k_rule --tracef=./dts/dep/test-acl-input/a
cl1v4_10k_trace --iter=1 --verbose=3 --rulenum=100000 --tracenum=100000 --bpf="1301:1302:1303"

ip netns exec ns1 bpftool map lookup name acl_rule key 1 0 0 0
{
    "key": 1,
    "value": {
        "id": 1,
        "action": "XDP_DROP",
        "rule": {
            "proto": 6,
            "proto_mask": 255,
            "ip_src": 2935011105,
            "ip_src_mask_len": 32,
            "ip_dst": 1568679036,
            "ip_dst_mask_len": 32,
            "port_src_low": 0,
            "port_src_high": 65535,
            "port_dst_low": 443,
            "port_dst_high": 443
        },
        "num_packet": 0
    }
}

That should match first rule in corresponding --rulesf file.

ip netns exec ns2 time python3 ./scripts/send_pcap_u6.py /home/kananyev/test/acl/acl1v4_10k_trace_u1.pcap eth9 20000 10

ip netns exec ns1 bpftool map lookup name acl_rule key 1 0 0 0
{
    "key": 1,
    "value": {
        "id": 1,
        "action": "XDP_DROP",
        "rule": {
            "proto": 6,
            "proto_mask": 255,
            "ip_src": 2935011105,
            "ip_src_mask_len": 32,
            "ip_dst": 1568679036,
            "ip_dst_mask_len": 32,
            "port_src_low": 0,
            "port_src_high": 65535,
            "port_dst_low": 443,
            "port_dst_high": 443
        },
        "num_packet": 19
    }
}

Signed-off-by: Konstantin Ananyev <konstantin.ananyev@huawei.com>
---
 app/acl-bpf/acl_internal.h |   49 ++
 app/acl-bpf/acl_xdp.h      |   67 ++
 app/acl-bpf/main.c         | 1311 ++++++++++++++++++++++++++++++++++++
 app/acl-bpf/meson.build    |   13 +
 app/acl-bpf/xdp_acl1.c     |  208 ++++++
 app/acl-bpf/xdp_acl2.c     |  288 ++++++++
 app/acl-bpf/xdp_acl3.c     |  289 ++++++++
 app/acl-bpf/xdp_acl4.c     |  257 +++++++
 app/acl-bpf/xdp_prog1.c    |   39 ++
 app/acl-bpf/xdp_timer1.c   |   69 ++
 app/meson.build            |    1 +
 app/test-acl/main.c        |  101 +--
 app/test-acl/xdp_timer1.c  |   69 ++
 lib/acl/acl_bpf.c          |  107 ++-
 lib/acl/rte_acl.h          |   31 +-
 15 files changed, 2731 insertions(+), 168 deletions(-)
 create mode 100644 app/acl-bpf/acl_internal.h
 create mode 100644 app/acl-bpf/acl_xdp.h
 create mode 100644 app/acl-bpf/main.c
 create mode 100644 app/acl-bpf/meson.build
 create mode 100644 app/acl-bpf/xdp_acl1.c
 create mode 100644 app/acl-bpf/xdp_acl2.c
 create mode 100644 app/acl-bpf/xdp_acl3.c
 create mode 100644 app/acl-bpf/xdp_acl4.c
 create mode 100644 app/acl-bpf/xdp_prog1.c
 create mode 100644 app/acl-bpf/xdp_timer1.c
 create mode 100644 app/test-acl/xdp_timer1.c

diff --git a/app/acl-bpf/acl_internal.h b/app/acl-bpf/acl_internal.h
new file mode 100644
index 0000000000..9367009ddb
--- /dev/null
+++ b/app/acl-bpf/acl_internal.h
@@ -0,0 +1,49 @@
+
+#ifndef _ACL_INTERNAL_H_
+#define _ACL_INTERNAL_H_
+
+/*
+ * !!! copy of internal defines from ACL library
+ * we need it here to implement exactly the same classify() method
+ * within our XDP program.
+ */
+
+/** Mask value of type "tp" for the first "ln" bit set. */
+#define RTE_LEN2MASK(ln, tp)    \
+	((tp)((uint64_t)-1 >> (sizeof(uint64_t) * CHAR_BIT - (ln))))
+
+enum {
+        RTE_ACL_TYPE_SHIFT = 29,
+        RTE_ACL_MAX_INDEX = RTE_LEN2MASK(RTE_ACL_TYPE_SHIFT, uint32_t),
+        RTE_ACL_MAX_PRIORITY = RTE_ACL_MAX_INDEX,
+        RTE_ACL_MIN_PRIORITY = 1,
+};
+
+#define RTE_ACL_NODE_DFA	(0 << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_SINGLE	(1U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_QRANGE	(3U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_MATCH	(4U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_TYPE	(7U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_UNDEFINED	UINT32_MAX
+
+#define RTE_ACL_QUAD_MAX	5
+#define RTE_ACL_QUAD_SIZE	4
+#define RTE_ACL_QUAD_SINGLE	UINT64_C(0x7f7f7f7f00000000)
+
+#define RTE_ACL_SINGLE_TRIE_SIZE	2000
+
+#define RTE_ACL_DFA_MAX		UINT8_MAX
+#define RTE_ACL_DFA_SIZE	(UINT8_MAX + 1)
+
+#define RTE_ACL_DFA_GR64_SIZE	64
+#define RTE_ACL_DFA_GR64_NUM	(RTE_ACL_DFA_SIZE / RTE_ACL_DFA_GR64_SIZE)
+#define RTE_ACL_DFA_GR64_BIT	\
+	(CHAR_BIT * sizeof(uint32_t) / RTE_ACL_DFA_GR64_NUM)
+
+#define RTE_ACL_NODE_INDEX	((uint32_t)~RTE_ACL_NODE_TYPE)
+
+#define SCALAR_QRANGE_MULT	0x01010101
+#define SCALAR_QRANGE_MASK	0x7f7f7f7f
+#define SCALAR_QRANGE_MIN	0x80808080
+
+#endif /* _ACL_INTERNAL_H_ */
diff --git a/app/acl-bpf/acl_xdp.h b/app/acl-bpf/acl_xdp.h
new file mode 100644
index 0000000000..1fc0f890f2
--- /dev/null
+++ b/app/acl-bpf/acl_xdp.h
@@ -0,0 +1,67 @@
+
+#ifndef _ACL_XDP_H_
+#define _ACL_XDP_H_
+
+/**
+ * Define common structures that are used both by user-space and XDP programs.
+ */
+
+/**
+ * IPv4 header fields we are searching through:
+ * - IP protocol value (8 bits)
+ * - IP source address (32 bits)
+ * - IP destination address (32 bits)
+ * - L4 protocol (UDP/TCP) source port number (16 bits)
+ * - L4 protocol (UDP/TCP) destination port number (16 bits)
+ */
+struct ipv4_5tuple {
+        uint8_t  proto;
+        uint32_t ip_src;
+        uint32_t ip_dst;
+        uint16_t port_src;
+        uint16_t port_dst;
+};
+
+struct ipv4_5tuple_rule {
+	uint8_t proto;                 /**< IPv4 protocol ID. */
+	uint8_t proto_mask;            /**< IPv4 protocol ID mask. */
+	uint32_t ip_src;               /**< IPv4 source address. */
+	uint32_t ip_src_mask_len;      /**< length of source address mask. */
+	uint32_t ip_dst;               /**< IPv4 dest address. */
+	uint32_t ip_dst_mask_len;      /**< length of dest address mask. */
+	uint16_t port_src_low;         /**< L4 source port low. */
+        uint16_t port_src_high;        /**< L4 source port high. */
+        uint16_t port_dst_low;         /**< L4 destination port low. */
+        uint16_t port_dst_high;        /**< L4 destination port high. */
+};
+
+struct ipv4_rule {
+	uint32_t id;
+	enum xdp_action action;
+	struct ipv4_5tuple_rule rule;
+	uint64_t num_packet;
+};
+
+/**
+ * IPv6 header fields we are searching through:
+ * - IP protocol value (8 bits)
+ * - IP source address (128 bits)
+ * - IP destination address (128 bits)
+ * - L4 protocol (UDP/TCP) source port number (16 bits)
+ * - L4 protocol (UDP/TCP) destination port number (16 bits)
+ */
+
+#define IPV6_ADDR_LEN   16
+#define IPV6_ADDR_U16   (IPV6_ADDR_LEN / sizeof(uint16_t))
+#define IPV6_ADDR_U32   (IPV6_ADDR_LEN / sizeof(uint32_t))
+#define IPV6_ADDR_U64   (IPV6_ADDR_LEN / sizeof(uint64_t))
+
+struct ipv6_5tuple {
+	uint8_t  proto;
+	uint32_t ip_src[IPV6_ADDR_U32];
+	uint32_t ip_dst[IPV6_ADDR_U32];
+	uint16_t port_src;
+	uint16_t port_dst;
+};
+
+#endif /* _ACL_XDP_H_ */
diff --git a/app/acl-bpf/main.c b/app/acl-bpf/main.c
new file mode 100644
index 0000000000..c2e613780a
--- /dev/null
+++ b/app/acl-bpf/main.c
@@ -0,0 +1,1311 @@
+/* SPDX-License-Identifier: BSD-3-Clause
+ * Copyright(c) 2010-2014 Intel Corporation
+ */
+
+#include <rte_string_fns.h>
+#include <rte_acl.h>
+#include <getopt.h>
+#include <string.h>
+#include <unistd.h>
+#include <bpf/bpf.h>
+
+#include <rte_cycles.h>
+#include <rte_per_lcore.h>
+#include <rte_lcore.h>
+#include <rte_ip.h>
+
+#include "acl_xdp.h"
+
+#define	PRINT_USAGE_START	"%s [EAL options] --\n"
+
+#define	RTE_LOGTYPE_TESTACL	RTE_LOGTYPE_USER1
+
+#define	APP_NAME	"TESTACL"
+
+#define GET_CB_FIELD(in, fd, base, lim, dlm)	do {            \
+	unsigned long val;                                      \
+	char *end_fld;                                          \
+	errno = 0;                                              \
+	val = strtoul((in), &end_fld, (base));                  \
+	if (errno != 0 || end_fld[0] != (dlm) || val > (lim))   \
+		return -EINVAL;                               \
+	(fd) = (typeof(fd))val;                                 \
+	(in) = end_fld + 1;                                     \
+} while (0)
+
+#define	OPT_RULE_FILE		"rulesf"
+#define	OPT_TRACE_FILE		"tracef"
+#define	OPT_RULE_NUM		"rulenum"
+#define	OPT_TRACE_NUM		"tracenum"
+#define	OPT_MAX_SIZE		"maxsize"
+#define	OPT_ITER_NUM		"iter"
+#define	OPT_VERBOSE		"verbose"
+#define	OPT_IPV6		"ipv6"
+#define	OPT_BPF			"bpf"
+
+#define	TRACE_DEFAULT_NUM	0x10000
+
+#define	RULE_NUM		0x10000
+
+#define COMMENT_LEAD_CHAR	'#'
+
+enum {
+	DUMP_NONE,
+	DUMP_SEARCH,
+	DUMP_PKT,
+	DUMP_MAX
+};
+
+enum {
+	IPV6_FRMT_NONE,
+	IPV6_FRMT_U32,
+	IPV6_FRMT_U64,
+};
+
+struct bpf_conf {	
+	struct rte_acl_bpf_id bpid;
+	struct rte_acl_bpf_fd bpfd;
+};
+
+static struct {
+	const char         *prgname;
+	const char         *rule_file;
+	const char         *trace_file;
+	size_t              max_size;
+	uint32_t            bld_categories;
+	uint32_t            run_categories;
+	uint32_t            nb_rules;
+	uint32_t            nb_traces;
+	uint32_t            trace_sz;
+	uint32_t            iter_num;
+	uint32_t            verbose;
+	uint32_t            ipv6;
+	uint32_t            used_traces;
+	void               *traces;
+	struct rte_acl_ctx *acx;
+	struct bpf_conf bpf;
+} config = {
+	.bld_categories = 3,
+	.run_categories = 1,
+	.nb_rules = RULE_NUM,
+	.nb_traces = TRACE_DEFAULT_NUM,
+	.iter_num = 1,
+	.verbose = DUMP_MAX,
+	.ipv6 = IPV6_FRMT_NONE,
+};
+
+static struct rte_acl_param prm = {
+	.name = APP_NAME,
+	.socket_id = SOCKET_ID_ANY,
+};
+
+/*
+ * Rule and trace formats definitions.
+ */
+
+enum {
+	PROTO_FIELD_IPV4,
+	SRC_FIELD_IPV4,
+	DST_FIELD_IPV4,
+	SRCP_FIELD_IPV4,
+	DSTP_FIELD_IPV4,
+	NUM_FIELDS_IPV4
+};
+
+/*
+ * That effectively defines order of IPV4VLAN classifications:
+ *  - PROTO
+ *  - VLAN (TAG and DOMAIN)
+ *  - SRC IP ADDRESS
+ *  - DST IP ADDRESS
+ *  - PORTS (SRC and DST)
+ */
+enum {
+	RTE_ACL_IPV4VLAN_PROTO,
+	RTE_ACL_IPV4VLAN_VLAN,
+	RTE_ACL_IPV4VLAN_SRC,
+	RTE_ACL_IPV4VLAN_DST,
+	RTE_ACL_IPV4VLAN_PORTS,
+	RTE_ACL_IPV4VLAN_NUM
+};
+
+struct rte_acl_field_def ipv4_defs[NUM_FIELDS_IPV4] = {
+	{
+		.type = RTE_ACL_FIELD_TYPE_BITMASK,
+		.size = sizeof(uint8_t),
+		.field_index = PROTO_FIELD_IPV4,
+		.input_index = RTE_ACL_IPV4VLAN_PROTO,
+		.offset = offsetof(struct ipv4_5tuple, proto),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = SRC_FIELD_IPV4,
+		.input_index = RTE_ACL_IPV4VLAN_SRC,
+		.offset = offsetof(struct ipv4_5tuple, ip_src),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = DST_FIELD_IPV4,
+		.input_index = RTE_ACL_IPV4VLAN_DST,
+		.offset = offsetof(struct ipv4_5tuple, ip_dst),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_RANGE,
+		.size = sizeof(uint16_t),
+		.field_index = SRCP_FIELD_IPV4,
+		.input_index = RTE_ACL_IPV4VLAN_PORTS,
+		.offset = offsetof(struct ipv4_5tuple, port_src),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_RANGE,
+		.size = sizeof(uint16_t),
+		.field_index = DSTP_FIELD_IPV4,
+		.input_index = RTE_ACL_IPV4VLAN_PORTS,
+		.offset = offsetof(struct ipv4_5tuple, port_dst),
+	},
+};
+
+/* treat IPV6 address as uint32_t[4] (default mode) */
+enum {
+	PROTO_FIELD_IPV6,
+	SRC1_FIELD_IPV6,
+	SRC2_FIELD_IPV6,
+	SRC3_FIELD_IPV6,
+	SRC4_FIELD_IPV6,
+	DST1_FIELD_IPV6,
+	DST2_FIELD_IPV6,
+	DST3_FIELD_IPV6,
+	DST4_FIELD_IPV6,
+	SRCP_FIELD_IPV6,
+	DSTP_FIELD_IPV6,
+	NUM_FIELDS_IPV6
+};
+
+/* treat IPV6 address as uint64_t[2] (default mode) */
+enum {
+	PROTO_FIELD_IPV6_U64,
+	SRC1_FIELD_IPV6_U64,
+	SRC2_FIELD_IPV6_U64,
+	DST1_FIELD_IPV6_U64,
+	DST2_FIELD_IPV6_U64,
+	SRCP_FIELD_IPV6_U64,
+	DSTP_FIELD_IPV6_U64,
+	NUM_FIELDS_IPV6_U64
+};
+
+enum {
+	PROTO_INDEX_IPV6_U64 = PROTO_FIELD_IPV6_U64,
+	SRC1_INDEX_IPV6_U64 = SRC1_FIELD_IPV6_U64,
+	SRC2_INDEX_IPV6_U64 = SRC2_FIELD_IPV6_U64 + 1,
+	DST1_INDEX_IPV6_U64 = DST1_FIELD_IPV6_U64 + 2,
+	DST2_INDEX_IPV6_U64 = DST2_FIELD_IPV6_U64 + 3,
+	PRT_INDEX_IPV6_U64 = SRCP_FIELD_IPV6 + 4,
+};
+
+struct rte_acl_field_def ipv6_defs[NUM_FIELDS_IPV6] = {
+	{
+		.type = RTE_ACL_FIELD_TYPE_BITMASK,
+		.size = sizeof(uint8_t),
+		.field_index = PROTO_FIELD_IPV6,
+		.input_index = PROTO_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, proto),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = SRC1_FIELD_IPV6,
+		.input_index = SRC1_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, ip_src[0]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = SRC2_FIELD_IPV6,
+		.input_index = SRC2_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, ip_src[1]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = SRC3_FIELD_IPV6,
+		.input_index = SRC3_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, ip_src[2]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = SRC4_FIELD_IPV6,
+		.input_index = SRC4_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, ip_src[3]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = DST1_FIELD_IPV6,
+		.input_index = DST1_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, ip_dst[0]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = DST2_FIELD_IPV6,
+		.input_index = DST2_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, ip_dst[1]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = DST3_FIELD_IPV6,
+		.input_index = DST3_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, ip_dst[2]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint32_t),
+		.field_index = DST4_FIELD_IPV6,
+		.input_index = DST4_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, ip_dst[3]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_RANGE,
+		.size = sizeof(uint16_t),
+		.field_index = SRCP_FIELD_IPV6,
+		.input_index = SRCP_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, port_src),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_RANGE,
+		.size = sizeof(uint16_t),
+		.field_index = DSTP_FIELD_IPV6,
+		.input_index = SRCP_FIELD_IPV6,
+		.offset = offsetof(struct ipv6_5tuple, port_dst),
+	},
+};
+
+struct rte_acl_field_def ipv6_u64_defs[NUM_FIELDS_IPV6_U64] = {
+	{
+		.type = RTE_ACL_FIELD_TYPE_BITMASK,
+		.size = sizeof(uint8_t),
+		.field_index = PROTO_FIELD_IPV6_U64,
+		.input_index = PROTO_FIELD_IPV6_U64,
+		.offset = offsetof(struct ipv6_5tuple, proto),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint64_t),
+		.field_index = SRC1_FIELD_IPV6_U64,
+		.input_index = SRC1_INDEX_IPV6_U64,
+		.offset = offsetof(struct ipv6_5tuple, ip_src[0]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint64_t),
+		.field_index = SRC2_FIELD_IPV6_U64,
+		.input_index = SRC2_INDEX_IPV6_U64,
+		.offset = offsetof(struct ipv6_5tuple, ip_src[2]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint64_t),
+		.field_index = DST1_FIELD_IPV6_U64,
+		.input_index = DST1_INDEX_IPV6_U64,
+		.offset = offsetof(struct ipv6_5tuple, ip_dst[0]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_MASK,
+		.size = sizeof(uint64_t),
+		.field_index = DST2_FIELD_IPV6_U64,
+		.input_index = DST2_INDEX_IPV6_U64,
+		.offset = offsetof(struct ipv6_5tuple, ip_dst[2]),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_RANGE,
+		.size = sizeof(uint16_t),
+		.field_index = SRCP_FIELD_IPV6_U64,
+		.input_index = PRT_INDEX_IPV6_U64,
+		.offset = offsetof(struct ipv6_5tuple, port_src),
+	},
+	{
+		.type = RTE_ACL_FIELD_TYPE_RANGE,
+		.size = sizeof(uint16_t),
+		.field_index = DSTP_FIELD_IPV6_U64,
+		.input_index = PRT_INDEX_IPV6_U64,
+		.offset = offsetof(struct ipv6_5tuple, port_dst),
+	},
+};
+
+enum {
+	CB_FLD_SRC_ADDR,
+	CB_FLD_DST_ADDR,
+	CB_FLD_SRC_PORT_LOW,
+	CB_FLD_SRC_PORT_DLM,
+	CB_FLD_SRC_PORT_HIGH,
+	CB_FLD_DST_PORT_LOW,
+	CB_FLD_DST_PORT_DLM,
+	CB_FLD_DST_PORT_HIGH,
+	CB_FLD_PROTO,
+	CB_FLD_NUM,
+};
+
+enum {
+	CB_TRC_SRC_ADDR,
+	CB_TRC_DST_ADDR,
+	CB_TRC_SRC_PORT,
+	CB_TRC_DST_PORT,
+	CB_TRC_PROTO,
+	CB_TRC_NUM,
+};
+
+RTE_ACL_RULE_DEF(acl_rule, RTE_ACL_MAX_FIELDS);
+
+static const char cb_port_delim[] = ":";
+
+static char line[LINE_MAX];
+
+#define	dump_verbose(lvl, fh, fmt, ...)	do { \
+	if ((lvl) <= (int32_t)config.verbose)        \
+		fprintf(fh, fmt, ##__VA_ARGS__);         \
+} while (0)
+
+
+/*
+ * Parse ClassBench input trace (test vectors and expected results) file.
+ * Expected format:
+ * <src_ipv4_addr> <space> <dst_ipv4_addr> <space> \
+ * <src_port> <space> <dst_port> <space> <proto>
+ */
+static int
+parse_cb_ipv4_trace(char *str, struct ipv4_5tuple *v)
+{
+	int i;
+	char *s, *sp, *in[CB_TRC_NUM];
+	static const char *dlm = " \t\n";
+
+	s = str;
+	for (i = 0; i != RTE_DIM(in); i++) {
+		in[i] = strtok_r(s, dlm, &sp);
+		if (in[i] == NULL)
+			return -EINVAL;
+		s = NULL;
+	}
+
+	GET_CB_FIELD(in[CB_TRC_SRC_ADDR], v->ip_src, 0, UINT32_MAX, 0);
+	GET_CB_FIELD(in[CB_TRC_DST_ADDR], v->ip_dst, 0, UINT32_MAX, 0);
+	GET_CB_FIELD(in[CB_TRC_SRC_PORT], v->port_src, 0, UINT16_MAX, 0);
+	GET_CB_FIELD(in[CB_TRC_DST_PORT], v->port_dst, 0, UINT16_MAX, 0);
+	GET_CB_FIELD(in[CB_TRC_PROTO], v->proto, 0, UINT8_MAX, 0);
+
+	/* convert to network byte order. */
+	v->ip_src = rte_cpu_to_be_32(v->ip_src);
+	v->ip_dst = rte_cpu_to_be_32(v->ip_dst);
+	v->port_src = rte_cpu_to_be_16(v->port_src);
+	v->port_dst = rte_cpu_to_be_16(v->port_dst);
+
+	return 0;
+}
+
+static int
+parse_cb_ipv6_addr_trace(const char *in, uint32_t v[IPV6_ADDR_U32])
+{
+	if (inet_pton(AF_INET6, in, v) != 1)
+		return -EINVAL;
+
+	return 0;
+}
+
+/*
+ * Parse ClassBench input trace (test vectors and expected results) file.
+ * Expected format:
+ * <src_ipv6_addr> <space> <dst_ipv6_addr> <space> \
+ * <src_port> <space> <dst_port> <space> <proto>
+ */
+static int
+parse_cb_ipv6_trace(char *str, struct ipv6_5tuple *v)
+{
+	int32_t i, rc;
+	char *s, *sp, *in[CB_TRC_NUM];
+	static const char *dlm = " \t\n";
+
+	s = str;
+	for (i = 0; i != RTE_DIM(in); i++) {
+		in[i] = strtok_r(s, dlm, &sp);
+		if (in[i] == NULL)
+			return -EINVAL;
+		s = NULL;
+	}
+
+	/* get ip6 src address. */
+	rc = parse_cb_ipv6_addr_trace(in[CB_TRC_SRC_ADDR], v->ip_src);
+	if (rc != 0)
+		return rc;
+
+	/* get ip6 dst address. */
+	rc = parse_cb_ipv6_addr_trace(in[CB_TRC_DST_ADDR], v->ip_dst);
+	if (rc != 0)
+		return rc;
+
+	GET_CB_FIELD(in[CB_TRC_SRC_PORT], v->port_src, 0, UINT16_MAX, 0);
+	GET_CB_FIELD(in[CB_TRC_DST_PORT], v->port_dst, 0, UINT16_MAX, 0);
+	GET_CB_FIELD(in[CB_TRC_PROTO], v->proto, 0, UINT8_MAX, 0);
+
+	/* convert to network byte order. */
+	v->port_src = rte_cpu_to_be_16(v->port_src);
+	v->port_dst = rte_cpu_to_be_16(v->port_dst);
+
+	return 0;
+}
+
+/* Bypass comment and empty lines */
+static int
+skip_line(const char *buf)
+{
+	uint32_t i;
+
+	for (i = 0; isspace(buf[i]) != 0; i++)
+		;
+
+	if (buf[i] == 0 || buf[i] == COMMENT_LEAD_CHAR)
+		return 1;
+
+	return 0;
+}
+
+static void
+tracef_init(void)
+{
+	static const char name[] = APP_NAME;
+	FILE *f;
+	size_t sz;
+	uint32_t i, k, n;
+	struct ipv4_5tuple *v;
+	struct ipv6_5tuple *w;
+
+	sz = config.nb_traces * (config.ipv6 ? sizeof(*w) : sizeof(*v));
+	config.traces = rte_zmalloc_socket(name, sz, RTE_CACHE_LINE_SIZE,
+			SOCKET_ID_ANY);
+	if (config.traces == NULL)
+		rte_exit(EXIT_FAILURE, "Cannot allocate %zu bytes for "
+			"requested %u number of trace records\n",
+			sz, config.nb_traces);
+
+	f = fopen(config.trace_file, "r");
+	if (f == NULL)
+		rte_exit(-EINVAL, "failed to open file: %s\n",
+			config.trace_file);
+
+	v = config.traces;
+	w = config.traces;
+	k = 0;
+	n = 0;
+	for (i = 0; n != config.nb_traces; i++) {
+
+		if (fgets(line, sizeof(line), f) == NULL)
+			break;
+
+		if (skip_line(line) != 0) {
+			k++;
+			continue;
+		}
+
+		n = i - k;
+
+		if (config.ipv6) {
+			if (parse_cb_ipv6_trace(line, w + n) != 0)
+				rte_exit(EXIT_FAILURE,
+					"%s: failed to parse ipv6 trace "
+					"record at line %u\n",
+					config.trace_file, i + 1);
+		} else {
+			if (parse_cb_ipv4_trace(line, v + n) != 0)
+				rte_exit(EXIT_FAILURE,
+					"%s: failed to parse ipv4 trace "
+					"record at line %u\n",
+					config.trace_file, i + 1);
+		}
+	}
+
+	config.used_traces = i - k;
+	fclose(f);
+}
+
+static int
+parse_ipv6_u32_net(char *in, struct rte_acl_field field[IPV6_ADDR_U32])
+{
+	char *sa, *sm, *sv;
+	uint32_t i, m, v[IPV6_ADDR_U32];
+
+	const char *dlm = "/";
+	const uint32_t nbu32 = sizeof(uint32_t) * CHAR_BIT;
+
+	/* get address. */
+	sv = NULL;
+	sa = strtok_r(in, dlm, &sv);
+	if (sa == NULL)
+		return -EINVAL;
+	sm = strtok_r(NULL, dlm, &sv);
+	if (sm == NULL)
+		return -EINVAL;
+
+	if (inet_pton(AF_INET6, sa, v) != 1)
+		return -EINVAL;
+
+	v[0] = rte_be_to_cpu_32(v[0]);
+	v[1] = rte_be_to_cpu_32(v[1]);
+	v[2] = rte_be_to_cpu_32(v[2]);
+	v[3] = rte_be_to_cpu_32(v[3]);
+
+	/* get mask. */
+	GET_CB_FIELD(sm, m, 0, CHAR_BIT * sizeof(v), 0);
+
+	/* put all together. */
+	for (i = 0; i != RTE_DIM(v); i++) {
+		if (m >= (i + 1) * nbu32)
+			field[i].mask_range.u32 = nbu32;
+		else
+			field[i].mask_range.u32 = m > (i * nbu32) ?
+				m - (i * nbu32) : 0;
+
+		field[i].value.u32 = v[i];
+	}
+
+	return 0;
+}
+
+static int
+parse_ipv6_u64_net(char *in, struct rte_acl_field field[IPV6_ADDR_U64])
+{
+	char *sa, *sm, *sv;
+	uint32_t i, m;
+	uint64_t v[IPV6_ADDR_U64];
+
+	const char *dlm = "/";
+	const uint32_t nbu64 = sizeof(uint64_t) * CHAR_BIT;
+
+	/* get address. */
+	sv = NULL;
+	sa = strtok_r(in, dlm, &sv);
+	if (sa == NULL)
+		return -EINVAL;
+	sm = strtok_r(NULL, dlm, &sv);
+	if (sm == NULL)
+		return -EINVAL;
+
+	if (inet_pton(AF_INET6, sa, v) != 1)
+		return -EINVAL;
+
+	v[0] = rte_be_to_cpu_64(v[0]);
+	v[1] = rte_be_to_cpu_64(v[1]);
+
+	/* get mask. */
+	GET_CB_FIELD(sm, m, 0, CHAR_BIT * sizeof(v), 0);
+
+	/* put all together. */
+	for (i = 0; i != RTE_DIM(v); i++) {
+		if (m >= (i + 1) * nbu64)
+			field[i].mask_range.u32 = nbu64;
+		else
+			field[i].mask_range.u32 = m > (i * nbu64) ?
+				m - (i * nbu64) : 0;
+
+		field[i].value.u64 = v[i];
+	}
+
+	return 0;
+}
+
+static int
+parse_cb_ipv6_rule(char *str, struct acl_rule *v, int frmt)
+{
+	int i, rc;
+	uint32_t fidx;
+	const uint32_t *field_map;
+	char *s, *sp, *in[CB_FLD_NUM];
+	int (*parse_ipv6_net)(char *s, struct rte_acl_field f[]);
+
+	static const char *dlm = " \t\n";
+
+	static const uint32_t field_map_u32[CB_FLD_NUM] = {
+		[CB_FLD_SRC_ADDR] = SRC1_FIELD_IPV6,
+		[CB_FLD_DST_ADDR] = DST1_FIELD_IPV6,
+		[CB_FLD_SRC_PORT_LOW] = SRCP_FIELD_IPV6,
+		[CB_FLD_SRC_PORT_HIGH] = SRCP_FIELD_IPV6,
+		[CB_FLD_DST_PORT_LOW] = DSTP_FIELD_IPV6,
+		[CB_FLD_DST_PORT_HIGH] = DSTP_FIELD_IPV6,
+		[CB_FLD_PROTO] = PROTO_FIELD_IPV6,
+	};
+
+	static const uint32_t field_map_u64[CB_FLD_NUM] = {
+		[CB_FLD_SRC_ADDR] = SRC1_FIELD_IPV6_U64,
+		[CB_FLD_DST_ADDR] = DST1_FIELD_IPV6_U64,
+		[CB_FLD_SRC_PORT_LOW] = SRCP_FIELD_IPV6_U64,
+		[CB_FLD_SRC_PORT_HIGH] = SRCP_FIELD_IPV6_U64,
+		[CB_FLD_DST_PORT_LOW] = DSTP_FIELD_IPV6_U64,
+		[CB_FLD_DST_PORT_HIGH] = DSTP_FIELD_IPV6_U64,
+		[CB_FLD_PROTO] = PROTO_FIELD_IPV6_U64,
+	};
+
+	if (frmt == IPV6_FRMT_U32) {
+		field_map = field_map_u32;
+		parse_ipv6_net = parse_ipv6_u32_net;
+	} else if (frmt == IPV6_FRMT_U64) {
+		field_map = field_map_u64;
+		parse_ipv6_net = parse_ipv6_u64_net;
+	} else
+		return -ENOTSUP;
+
+	/*
+	 * Skip leading '@'
+	 */
+	if (strchr(str, '@') != str)
+		return -EINVAL;
+
+	s = str + 1;
+
+	for (i = 0; i != RTE_DIM(in); i++) {
+		in[i] = strtok_r(s, dlm, &sp);
+		if (in[i] == NULL)
+			return -EINVAL;
+		s = NULL;
+	}
+
+	fidx = CB_FLD_SRC_ADDR;
+	rc = parse_ipv6_net(in[fidx], v->field + field_map[fidx]);
+	if (rc != 0) {
+		RTE_LOG(ERR, TESTACL,
+			"failed to read source address/mask: %s\n", in[fidx]);
+		return rc;
+	}
+
+	fidx = CB_FLD_DST_ADDR;
+	rc = parse_ipv6_net(in[fidx], v->field + field_map[fidx]);
+	if (rc != 0) {
+		RTE_LOG(ERR, TESTACL,
+			"failed to read destination address/mask: %s\n",
+			in[fidx]);
+		return rc;
+	}
+
+	/* source port. */
+	fidx = CB_FLD_SRC_PORT_LOW;
+	GET_CB_FIELD(in[fidx], v->field[field_map[fidx]].value.u16,
+		0, UINT16_MAX, 0);
+
+	fidx = CB_FLD_SRC_PORT_HIGH;
+	GET_CB_FIELD(in[fidx], v->field[field_map[fidx]].mask_range.u16,
+		0, UINT16_MAX, 0);
+
+	if (strncmp(in[CB_FLD_SRC_PORT_DLM], cb_port_delim,
+			sizeof(cb_port_delim)) != 0)
+		return -EINVAL;
+
+	/* destination port. */
+	fidx = CB_FLD_DST_PORT_LOW;
+	GET_CB_FIELD(in[fidx], v->field[field_map[fidx]].value.u16,
+		0, UINT16_MAX, 0);
+
+	fidx = CB_FLD_DST_PORT_HIGH;
+	GET_CB_FIELD(in[fidx], v->field[field_map[fidx]].mask_range.u16,
+		0, UINT16_MAX, 0);
+
+	if (strncmp(in[CB_FLD_DST_PORT_DLM], cb_port_delim,
+			sizeof(cb_port_delim)) != 0)
+		return -EINVAL;
+
+	fidx = CB_FLD_PROTO;
+	GET_CB_FIELD(in[fidx], v->field[field_map[fidx]].value.u8,
+		0, UINT8_MAX, '/');
+	GET_CB_FIELD(in[fidx], v->field[field_map[fidx]].mask_range.u8,
+		0, UINT8_MAX, 0);
+
+	return 0;
+}
+
+static int
+parse_cb_ipv6_u32_rule(char *str, struct acl_rule *v)
+{
+	return parse_cb_ipv6_rule(str, v, IPV6_FRMT_U32);
+}
+
+static int
+parse_cb_ipv6_u64_rule(char *str, struct acl_rule *v)
+{
+	return parse_cb_ipv6_rule(str, v, IPV6_FRMT_U64);
+}
+
+static int
+parse_ipv4_net(char *in, uint32_t *addr, uint32_t *mask_len)
+{
+	char *sa, *sm, *sv;
+	uint32_t m, v;
+
+	const char *dlm = "/";
+
+	sv = NULL;
+	sa = strtok_r(in, dlm, &sv);
+	if (sa == NULL)
+		return -EINVAL;
+	sm = strtok_r(NULL, dlm, &sv);
+	if (sm == NULL)
+		return -EINVAL;
+
+	if (inet_pton(AF_INET, sa, &v) != 1)
+		return -EINVAL;
+
+	addr[0] = rte_be_to_cpu_32(v);
+
+	GET_CB_FIELD(sm, m, 0, sizeof(uint32_t) * CHAR_BIT, 0);
+	mask_len[0] = m;
+
+	return 0;
+}
+/*
+ * Parse ClassBench rules file.
+ * Expected format:
+ * '@'<src_ipv4_addr>'/'<masklen> <space> \
+ * <dst_ipv4_addr>'/'<masklen> <space> \
+ * <src_port_low> <space> ":" <src_port_high> <space> \
+ * <dst_port_low> <space> ":" <dst_port_high> <space> \
+ * <proto>'/'<mask>
+ */
+static int
+parse_cb_ipv4_rule(char *str, struct acl_rule *v)
+{
+	int i, rc;
+	char *s, *sp, *in[CB_FLD_NUM];
+	static const char *dlm = " \t\n";
+
+	/*
+	 * Skip leading '@'
+	 */
+	if (strchr(str, '@') != str)
+		return -EINVAL;
+
+	s = str + 1;
+
+	for (i = 0; i != RTE_DIM(in); i++) {
+		in[i] = strtok_r(s, dlm, &sp);
+		if (in[i] == NULL)
+			return -EINVAL;
+		s = NULL;
+	}
+
+	rc = parse_ipv4_net(in[CB_FLD_SRC_ADDR],
+			&v->field[SRC_FIELD_IPV4].value.u32,
+			&v->field[SRC_FIELD_IPV4].mask_range.u32);
+	if (rc != 0) {
+		RTE_LOG(ERR, TESTACL,
+			"failed to read source address/mask: %s\n",
+			in[CB_FLD_SRC_ADDR]);
+		return rc;
+	}
+
+	rc = parse_ipv4_net(in[CB_FLD_DST_ADDR],
+			&v->field[DST_FIELD_IPV4].value.u32,
+			&v->field[DST_FIELD_IPV4].mask_range.u32);
+	if (rc != 0) {
+		RTE_LOG(ERR, TESTACL,
+			"failed to read destination address/mask: %s\n",
+			in[CB_FLD_DST_ADDR]);
+		return rc;
+	}
+
+	/* source port. */
+	GET_CB_FIELD(in[CB_FLD_SRC_PORT_LOW],
+		v->field[SRCP_FIELD_IPV4].value.u16,
+		0, UINT16_MAX, 0);
+	GET_CB_FIELD(in[CB_FLD_SRC_PORT_HIGH],
+		v->field[SRCP_FIELD_IPV4].mask_range.u16,
+		0, UINT16_MAX, 0);
+
+	if (strncmp(in[CB_FLD_SRC_PORT_DLM], cb_port_delim,
+			sizeof(cb_port_delim)) != 0)
+		return -EINVAL;
+
+	/* destination port. */
+	GET_CB_FIELD(in[CB_FLD_DST_PORT_LOW],
+		v->field[DSTP_FIELD_IPV4].value.u16,
+		0, UINT16_MAX, 0);
+	GET_CB_FIELD(in[CB_FLD_DST_PORT_HIGH],
+		v->field[DSTP_FIELD_IPV4].mask_range.u16,
+		0, UINT16_MAX, 0);
+
+	if (strncmp(in[CB_FLD_DST_PORT_DLM], cb_port_delim,
+			sizeof(cb_port_delim)) != 0)
+		return -EINVAL;
+
+	GET_CB_FIELD(in[CB_FLD_PROTO], v->field[PROTO_FIELD_IPV4].value.u8,
+		0, UINT8_MAX, '/');
+	GET_CB_FIELD(in[CB_FLD_PROTO], v->field[PROTO_FIELD_IPV4].mask_range.u8,
+		0, UINT8_MAX, 0);
+
+	return 0;
+}
+
+typedef int (*parse_5tuple)(char *text, struct acl_rule *rule);
+
+static int
+acl_add_map_ipv4_rule(int32_t mapfd, const struct acl_rule *p,
+	enum xdp_action action)
+{
+	int32_t rc;
+	struct ipv4_rule rule;
+
+	/* convert rule to xdp map format */
+	memset(&rule, 0, sizeof(rule));
+	rule.id = p->data.userdata;
+	rule.action = action;
+
+	/* proto */
+	rule.rule.proto = p->field[PROTO_FIELD_IPV4].value.u8;
+	rule.rule.proto_mask = p->field[PROTO_FIELD_IPV4].mask_range.u8;
+
+	/* src ip and mask */
+	rule.rule.ip_src = p->field[SRC_FIELD_IPV4].value.u32;
+	rule.rule.ip_src_mask_len = p->field[SRC_FIELD_IPV4].mask_range.u32;
+
+	/* dst ip and mask */
+	rule.rule.ip_dst = p->field[DST_FIELD_IPV4].value.u32;
+	rule.rule.ip_dst_mask_len = p->field[DST_FIELD_IPV4].mask_range.u32;
+
+	/* src L4 ports */
+	rule.rule.port_src_low = p->field[SRCP_FIELD_IPV4].value.u16;
+	rule.rule.port_src_high = p->field[SRCP_FIELD_IPV4].mask_range.u16;
+
+	/* dst L4 ports */
+	rule.rule.port_dst_low = p->field[DSTP_FIELD_IPV4].value.u16;
+	rule.rule.port_dst_high = p->field[DSTP_FIELD_IPV4].mask_range.u16;
+
+	rc = bpf_map_update_elem(mapfd, &rule.id, &rule, BPF_ANY);
+	if (rc != 0) {
+		printf("%s:%d  "
+			"bpf_map_update_elem(fd=%d, key=%u "
+			" failed, rc=%d, errno=%d\n",
+			__func__, __LINE__,
+			mapfd, rule.id, rc, errno);
+	}
+
+	return rc;
+}
+
+static int
+add_cb_rules(FILE *f, struct rte_acl_ctx *ctx)
+{
+	int rc;
+	uint32_t i, k, n;
+	struct acl_rule v;
+	parse_5tuple parser;
+
+	static const parse_5tuple parser_func[] = {
+		[IPV6_FRMT_NONE] = parse_cb_ipv4_rule,
+		[IPV6_FRMT_U32] = parse_cb_ipv6_u32_rule,
+		[IPV6_FRMT_U64] = parse_cb_ipv6_u64_rule,
+	};
+
+	memset(&v, 0, sizeof(v));
+	parser = parser_func[config.ipv6];
+
+	/* result zero means no match was found, so initialize 'no match' rule
+	 * with default action: PASS
+	 */
+	rc = acl_add_map_ipv4_rule(config.bpf.bpfd.rule_fd, &v, XDP_PASS);
+	if (rc != 0) {
+		RTE_LOG(ERR, TESTACL, "failed to add default rule "
+			"into XDP table, error code: %d (%s)\n",
+			rc, strerror(-rc));
+		return rc;
+	}
+
+	k = 0;
+	for (i = 1; fgets(line, sizeof(line), f) != NULL; i++) {
+
+		if (skip_line(line) != 0) {
+			k++;
+			continue;
+		}
+
+		n = i - k;
+		rc = parser(line, &v);
+		if (rc != 0) {
+			RTE_LOG(ERR, TESTACL, "line %u: parse_cb_ipv4vlan_rule"
+				" failed, error code: %d (%s)\n",
+				i, rc, strerror(-rc));
+			return rc;
+		}
+
+		v.data.category_mask = RTE_LEN2MASK(RTE_ACL_MAX_CATEGORIES,
+			typeof(v.data.category_mask));
+		v.data.priority = RTE_ACL_MAX_PRIORITY - n;
+		v.data.userdata = n;
+
+		rc = rte_acl_add_rules(ctx, (struct rte_acl_rule *)&v, 1);
+		if (rc != 0) {
+			RTE_LOG(ERR, TESTACL, "line %u: failed to add rules "
+				"into ACL context, error code: %d (%s)\n",
+				i, rc, strerror(-rc));
+			return rc;
+		}
+		rc = acl_add_map_ipv4_rule(config.bpf.bpfd.rule_fd, &v,
+			XDP_DROP);
+		if (rc != 0) {
+			RTE_LOG(ERR, TESTACL, "line %u: failed to add rules "
+				"into XDP table, error code: %d (%s)\n",
+				i, rc, strerror(-rc));
+			return rc;
+		}
+	}
+
+	return 0;
+}
+
+static void
+print_bpf_conf(const struct bpf_conf *cfg)
+{
+	printf("bpf_onf={\n");
+	printf("\tctx_id=%u,\n", cfg->bpid.ctx_id);
+	printf("\ttrans_id=%u,\n", cfg->bpid.trans_id);
+	printf("\trule_id=%u,\n", cfg->bpid.rule_id);
+	printf("\tctx_fd=%d,\n", cfg->bpfd.ctx_fd);
+	printf("\ttrans_fd=%d,\n", cfg->bpfd.trans_fd);
+	printf("\trule_fd=%d,\n", cfg->bpfd.rule_fd);
+	printf("}\n");
+}
+
+static void
+acx_init(void)
+{
+	int ret;
+	FILE *f;
+	struct rte_acl_config cfg;
+
+	memset(&cfg, 0, sizeof(cfg));
+
+	/* setup ACL build config. */
+	if (config.ipv6 == IPV6_FRMT_U32) {
+		cfg.num_fields = RTE_DIM(ipv6_defs);
+		memcpy(&cfg.defs, ipv6_defs, sizeof(ipv6_defs));
+	} else if (config.ipv6 == IPV6_FRMT_U64) {
+		cfg.num_fields = RTE_DIM(ipv6_u64_defs);
+		memcpy(&cfg.defs, ipv6_u64_defs, sizeof(ipv6_u64_defs));
+	} else {
+		cfg.num_fields = RTE_DIM(ipv4_defs);
+		memcpy(&cfg.defs, ipv4_defs, sizeof(ipv4_defs));
+	}
+	cfg.num_categories = config.bld_categories;
+	cfg.max_size = config.max_size;
+
+	/* setup ACL creation parameters. */
+	prm.rule_size = RTE_ACL_RULE_SZ(cfg.num_fields);
+	prm.max_rule_num = config.nb_rules;
+
+	config.acx = rte_acl_create(&prm);
+	if (config.acx == NULL)
+		rte_exit(rte_errno, "failed to create ACL context\n");
+
+	/* add ACL rules. */
+	f = fopen(config.rule_file, "r");
+	if (f == NULL)
+		rte_exit(-EINVAL, "failed to open file %s\n",
+			config.rule_file);
+
+	ret = add_cb_rules(f, config.acx);
+	if (ret != 0)
+		rte_exit(ret, "failed to add rules into ACL context\n");
+
+	fclose(f);
+
+	/* perform build. */
+	ret = rte_acl_build(config.acx, &cfg);
+
+	dump_verbose(DUMP_NONE, stdout,
+		"rte_acl_build(%u) finished with %d\n",
+		config.bld_categories, ret);
+
+	rte_acl_dump(config.acx);
+
+	ret = rte_acl_bpf_fill(&config.bpf.bpfd, config.acx);
+
+	if (ret != 0)
+		rte_exit(ret, "failed to build search context\n");
+}
+
+static uint32_t
+search_ip5tuples_once(uint32_t categories, uint32_t step)
+{
+	int ret;
+	uint32_t i, j, k, n, r;
+	const uint8_t *data[step], *v;
+	uint32_t results[step * categories];
+
+	v = config.traces;
+	for (i = 0; i != config.used_traces; i += n) {
+
+		n = RTE_MIN(step, config.used_traces - i);
+
+		for (j = 0; j != n; j++) {
+			data[j] = v;
+			v += config.trace_sz;
+		}
+
+		ret = 0;
+		for (j = 0; j != n && ret == 0; j++)
+			ret = rte_acl_bpf_classify(&config.bpf.bpfd,
+				data[j], config.trace_sz, results + j);
+
+		if (ret != 0)
+			rte_exit(ret, "classify for ipv%c_5tuples returns %d\n",
+				config.ipv6 ? '6' : '4', ret);
+
+		for (r = 0, j = 0; j != n; j++) {
+			for (k = 0; k != categories; k++, r++) {
+				dump_verbose(DUMP_PKT, stdout,
+					"ipv%c_5tuple: %u, category: %u, "
+					"result: %u\n",
+					config.ipv6 ? '6' : '4',
+					i + j + 1, k, results[r] - 1);
+			}
+
+		}
+	}
+
+	dump_verbose(DUMP_SEARCH, stdout,
+		"%s(%u, %u) returns %u\n", __func__,
+		categories, step, i);
+	return i;
+}
+
+static int
+search_ip5tuples(__rte_unused void *arg)
+{
+	uint64_t pkt, start, tm;
+	uint32_t i, lcore;
+	long double st;
+
+	lcore = rte_lcore_id();
+	start = rte_rdtsc_precise();
+	pkt = 0;
+
+	for (i = 0; i != config.iter_num; i++) {
+		pkt += search_ip5tuples_once(config.run_categories, 1);
+	}
+
+	tm = rte_rdtsc_precise() - start;
+
+	st = (long double)tm / rte_get_timer_hz();
+	dump_verbose(DUMP_NONE, stdout,
+		"%s  @lcore %u: %" PRIu32 " iterations, %" PRIu64 " pkts, %"
+		PRIu32 " categories, %" PRIu64 " cycles (%.2Lf sec), "
+		"%.2Lf cycles/pkt, %.2Lf pkt/sec\n",
+		__func__, lcore, i, pkt,
+		config.run_categories, tm, st,
+		(pkt == 0) ? 0 : (long double)tm / pkt, pkt / st);
+
+	return 0;
+}
+
+static unsigned long
+get_ulong_opt(const char *opt, const char *name, size_t min, size_t max)
+{
+	unsigned long val;
+	char *end;
+
+	errno = 0;
+	val = strtoul(opt, &end, 0);
+	if (errno != 0 || end[0] != 0 || val > max || val < min)
+		rte_exit(-EINVAL, "invalid value: \"%s\" for option: %s\n",
+			opt, name);
+	return val;
+}
+
+static int
+get_bpf_ids(struct bpf_conf *bpf, const char *opt)
+{
+	GET_CB_FIELD(opt, bpf->bpid.ctx_id, 0, UINT32_MAX, ':');
+	GET_CB_FIELD(opt, bpf->bpid.trans_id, 0, UINT32_MAX, ':');
+	GET_CB_FIELD(opt, bpf->bpid.rule_id, 0, UINT32_MAX, 0);
+	return 0;
+}
+
+static void
+get_bpf_opt(struct bpf_conf *bpf, const char *opt, const char *name)
+{
+	int32_t rc;
+
+	memset(bpf, 0, sizeof(*bpf));
+
+	rc = get_bpf_ids(bpf, opt);
+	if (rc != 0)
+		rte_exit(rc, "invalid value: \"%s\" for option: %s\n",
+			opt, name);
+}
+
+static void
+get_ipv6_opt(const char *opt, const char *name)
+{
+	uint32_t i;
+
+	static const struct {
+		const char *name;
+		uint32_t val;
+	} ipv6_opt[] = {
+		{
+			.name = "4B",
+			.val = IPV6_FRMT_U32,
+		},
+		{
+			.name = "8B",
+			.val = IPV6_FRMT_U64,
+		},
+	};
+
+	for (i = 0; i != RTE_DIM(ipv6_opt); i++) {
+		if (strcmp(opt, ipv6_opt[i].name) == 0) {
+			config.ipv6 = ipv6_opt[i].val;
+			return;
+		}
+	}
+
+	rte_exit(-EINVAL, "invalid value: \"%s\" for option: %s\n",
+		opt, name);
+}
+
+
+static void
+print_usage(const char *prgname)
+{
+	fprintf(stdout,
+		PRINT_USAGE_START
+		"--" OPT_RULE_FILE "=<rules set file>\n"
+		"[--" OPT_TRACE_FILE "=<input traces file>]\n"
+		"[--" OPT_RULE_NUM
+			"=<maximum number of rules for ACL context>]\n"
+		"[--" OPT_TRACE_NUM
+			"=<number of traces to read binary file in>]\n"
+		"[--" OPT_MAX_SIZE
+			"=<size limit (in bytes) for runtime ACL structures> "
+			"leave 0 for default behaviour]\n"
+		"[--" OPT_ITER_NUM "=<number of iterations to perform>]\n"
+		"[--" OPT_VERBOSE "=<verbose level>]\n"
+		"[--" OPT_IPV6 "(=4B | 8B) <IPv6 rules and trace files>]\n"
+		"[--" OPT_BPF
+			"(=test | <ctx_map_id:trans_map_id>:<rules_map_id>)\n",
+		prgname);
+}
+
+static void
+dump_config(FILE *f)
+{
+	fprintf(f, "%s:\n", __func__);
+	fprintf(f, "%s:%s\n", OPT_RULE_FILE, config.rule_file);
+	fprintf(f, "%s:%s\n", OPT_TRACE_FILE, config.trace_file);
+	fprintf(f, "%s:%u\n", OPT_RULE_NUM, config.nb_rules);
+	fprintf(f, "%s:%u\n", OPT_TRACE_NUM, config.nb_traces);
+	fprintf(f, "%s:%zu\n", OPT_MAX_SIZE, config.max_size);
+	fprintf(f, "%s:%u\n", OPT_ITER_NUM, config.iter_num);
+	fprintf(f, "%s:%u\n", OPT_VERBOSE, config.verbose);
+	fprintf(f, "%s:%u\n", OPT_IPV6, config.ipv6);
+}
+
+static void
+check_config(void)
+{
+	if (config.rule_file == NULL) {
+		print_usage(config.prgname);
+		rte_exit(-EINVAL, "mandatory option %s is not specified\n",
+			OPT_RULE_FILE);
+	}
+}
+
+
+static void
+get_input_opts(int argc, char **argv)
+{
+	static struct option lgopts[] = {
+		{OPT_RULE_FILE, 1, 0, 0},
+		{OPT_TRACE_FILE, 1, 0, 0},
+		{OPT_TRACE_NUM, 1, 0, 0},
+		{OPT_RULE_NUM, 1, 0, 0},
+		{OPT_MAX_SIZE, 1, 0, 0},
+		{OPT_ITER_NUM, 1, 0, 0},
+		{OPT_VERBOSE, 1, 0, 0},
+		{OPT_IPV6, 2, 0, 0},
+		{OPT_BPF, 1, 0, 0},
+		{NULL, 0, 0, 0}
+	};
+
+	int opt, opt_idx;
+
+	while ((opt = getopt_long(argc, argv, "", lgopts,  &opt_idx)) != EOF) {
+
+		if (opt != 0) {
+			print_usage(config.prgname);
+			rte_exit(-EINVAL, "unknown option: %c", opt);
+		}
+
+		if (strcmp(lgopts[opt_idx].name, OPT_RULE_FILE) == 0) {
+			config.rule_file = optarg;
+		} else if (strcmp(lgopts[opt_idx].name, OPT_TRACE_FILE) == 0) {
+			config.trace_file = optarg;
+		} else if (strcmp(lgopts[opt_idx].name, OPT_RULE_NUM) == 0) {
+			config.nb_rules = get_ulong_opt(optarg,
+				lgopts[opt_idx].name, 1, RTE_ACL_MAX_INDEX + 1);
+		} else if (strcmp(lgopts[opt_idx].name, OPT_MAX_SIZE) == 0) {
+			config.max_size = get_ulong_opt(optarg,
+				lgopts[opt_idx].name, 0, SIZE_MAX);
+		} else if (strcmp(lgopts[opt_idx].name, OPT_TRACE_NUM) == 0) {
+			config.nb_traces = get_ulong_opt(optarg,
+				lgopts[opt_idx].name, 1, UINT32_MAX);
+		} else if (strcmp(lgopts[opt_idx].name, OPT_ITER_NUM) == 0) {
+			config.iter_num = get_ulong_opt(optarg,
+				lgopts[opt_idx].name, 1, INT32_MAX);
+		} else if (strcmp(lgopts[opt_idx].name, OPT_VERBOSE) == 0) {
+			config.verbose = get_ulong_opt(optarg,
+				lgopts[opt_idx].name, DUMP_NONE, DUMP_MAX);
+		} else if (strcmp(lgopts[opt_idx].name, OPT_IPV6) == 0) {
+			config.ipv6 = IPV6_FRMT_U32;
+			if (optarg != NULL)
+				get_ipv6_opt(optarg, lgopts[opt_idx].name);
+		} else if (strcmp(lgopts[opt_idx].name, OPT_BPF) == 0) {
+			get_bpf_opt(&config.bpf, optarg, lgopts[opt_idx].name);
+		}
+	}
+	config.trace_sz = config.ipv6 ? sizeof(struct ipv6_5tuple) :
+						sizeof(struct ipv4_5tuple);
+
+}
+
+int
+main(int argc, char **argv)
+{
+	int ret;
+
+	ret = rte_eal_init(argc, argv);
+	if (ret < 0)
+		rte_panic("Cannot init EAL\n");
+
+	argc -= ret;
+	argv += ret;
+
+	config.prgname = argv[0];
+
+	get_input_opts(argc, argv);
+	dump_config(stdout);
+	check_config();
+
+	ret = rte_acl_bpf_open(&config.bpf.bpid, &config.bpf.bpfd);
+	print_bpf_conf(&config.bpf);
+	if (ret != 0)
+		return ret;
+
+	acx_init();
+
+	if (config.trace_file != NULL)
+		tracef_init();
+
+	search_ip5tuples(NULL);
+
+	rte_acl_bpf_close(&config.bpf.bpfd);
+	rte_acl_free(config.acx);
+	return 0;
+}
diff --git a/app/acl-bpf/meson.build b/app/acl-bpf/meson.build
new file mode 100644
index 0000000000..7d8b707794
--- /dev/null
+++ b/app/acl-bpf/meson.build
@@ -0,0 +1,13 @@
+# SPDX-License-Identifier: BSD-3-Clause
+# Copyright(c) 2019 Intel Corporation
+
+if is_windows
+    build = false
+    reason = 'not supported on Windows'
+    subdir_done()
+endif
+
+sources = files('main.c')
+deps += ['acl', 'net']
+
+cflags += no_wvla_cflag
diff --git a/app/acl-bpf/xdp_acl1.c b/app/acl-bpf/xdp_acl1.c
new file mode 100644
index 0000000000..567a835707
--- /dev/null
+++ b/app/acl-bpf/xdp_acl1.c
@@ -0,0 +1,208 @@
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/udp.h>
+#include <linux/tcp.h>
+
+#include <limits.h>
+#include <stdint.h>
+#include "acl_bpf.h"
+
+/*
+ * !!! copy of all defines - to remove
+ */
+
+/** Mask value of type "tp" for the first "ln" bit set. */
+#define RTE_LEN2MASK(ln, tp)    \
+	((tp)((uint64_t)-1 >> (sizeof(uint64_t) * CHAR_BIT - (ln))))
+
+enum {
+        RTE_ACL_TYPE_SHIFT = 29,
+        RTE_ACL_MAX_INDEX = RTE_LEN2MASK(RTE_ACL_TYPE_SHIFT, uint32_t),
+        RTE_ACL_MAX_PRIORITY = RTE_ACL_MAX_INDEX,
+        RTE_ACL_MIN_PRIORITY = 1,
+};
+
+#define RTE_ACL_NODE_DFA	(0 << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_SINGLE	(1U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_QRANGE	(3U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_MATCH	(4U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_TYPE	(7U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_UNDEFINED	UINT32_MAX
+
+#define RTE_ACL_QUAD_MAX	5
+#define RTE_ACL_QUAD_SIZE	4
+#define RTE_ACL_QUAD_SINGLE	UINT64_C(0x7f7f7f7f00000000)
+
+#define RTE_ACL_SINGLE_TRIE_SIZE	2000
+
+#define RTE_ACL_DFA_MAX		UINT8_MAX
+#define RTE_ACL_DFA_SIZE	(UINT8_MAX + 1)
+
+#define RTE_ACL_DFA_GR64_SIZE	64
+#define RTE_ACL_DFA_GR64_NUM	(RTE_ACL_DFA_SIZE / RTE_ACL_DFA_GR64_SIZE)
+#define RTE_ACL_DFA_GR64_BIT	\
+	(CHAR_BIT * sizeof(uint32_t) / RTE_ACL_DFA_GR64_NUM)
+
+#define RTE_ACL_NODE_INDEX	((uint32_t)~RTE_ACL_NODE_TYPE)
+
+#define SCALAR_QRANGE_MULT	0x01010101
+#define SCALAR_QRANGE_MASK	0x7f7f7f7f
+#define SCALAR_QRANGE_MIN	0x80808080
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, struct rte_acl_bpf_ctx);
+        __uint(max_entries, 1);
+} acl_ctx SEC(".maps");
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, uint64_t);
+        __uint(max_entries, 0x4000);
+} acl_trans SEC(".maps");
+
+struct packet_field {
+	uint8_t proto;
+	uint32_t src_ip;
+	uint32_t dst_ip;
+	uint16_t src_port;
+	uint16_t dst_port;
+};
+
+union packet_data {
+	struct packet_field data;
+	uint8_t raw[sizeof(struct packet_field)];
+};
+
+const uint32_t data_ofs[] = {
+	offsetof(struct packet_field, proto),
+	offsetof(struct packet_field, src_ip),
+	offsetof(struct packet_field, src_ip) + 1,
+	offsetof(struct packet_field, src_ip) + 2,
+	offsetof(struct packet_field, src_ip) + 3,
+	offsetof(struct packet_field, dst_ip),
+	offsetof(struct packet_field, dst_ip) + 1,
+	offsetof(struct packet_field, dst_ip) + 2,
+	offsetof(struct packet_field, dst_ip) + 3,
+	offsetof(struct packet_field, src_port),
+	offsetof(struct packet_field, src_port) + 1,
+	offsetof(struct packet_field, dst_port),
+	offsetof(struct packet_field, dst_port) + 1,
+};
+
+#define DIM(a)	(sizeof(a) / sizeof(a[0]))
+
+static inline uint32_t
+scan_forward(uint32_t input, uint32_t max)
+{
+	return (input == 0) ? max : __builtin_ctz(input);
+}
+
+static uint32_t
+resolve_next_index(uint64_t transition, uint8_t input)
+{
+	uint32_t addr, index, ranges, x, a, b, c;
+
+	/* break transition into component parts */
+	ranges = transition >> (sizeof(index) * CHAR_BIT);
+	index = transition & ~RTE_ACL_NODE_INDEX;
+	addr = transition ^ index;
+
+	if (index != RTE_ACL_NODE_DFA) {
+		/* calc address for a QRANGE/SINGLE node */
+		c = (uint32_t)input * SCALAR_QRANGE_MULT;
+		a = ranges | SCALAR_QRANGE_MIN;
+		a -= (c & SCALAR_QRANGE_MASK);
+		b = c & SCALAR_QRANGE_MIN;
+		a &= SCALAR_QRANGE_MIN;
+		a ^= (ranges ^ b) & (a ^ b);
+		x = scan_forward(a, 32) >> 3;
+	} else {
+		/* calc address for a DFA node */
+		x = ranges >> (input /
+			RTE_ACL_DFA_GR64_SIZE * RTE_ACL_DFA_GR64_BIT);
+		x &= UINT8_MAX;
+		x = input - x;
+	}
+
+	addr += x;
+	return addr;
+}
+
+
+SEC("xdp_prog")
+int xdp_acl_prog1(struct xdp_md *ctx)
+{
+	void *data_end;
+	void *data;
+	uint32_t i, idx, input, iphlen;
+	uint64_t trans;
+	const uint64_t *val;
+	struct ethhdr *eth;
+	struct iphdr *iph;
+	struct udphdr *udph;
+	union packet_data pd;
+	const struct rte_acl_bpf_ctx *bcx;
+
+	data_end = (void *)(long)ctx->data_end;
+	data = (void *)(long)ctx->data;
+
+	eth = data;
+	if (data + sizeof(*eth) > data_end)
+        	return XDP_DROP;
+
+	if (eth->h_proto != htons(ETH_P_IP))
+		return XDP_PASS;
+
+	iph = (struct iphdr *)(eth + 1);
+	if ((void *)(iph + 1) > data_end)
+		return XDP_DROP;
+
+	pd.data.proto = iph->protocol;
+	pd.data.src_ip = iph->saddr;
+	pd.data.dst_ip = iph->daddr;
+
+	iphlen = iph->ihl * sizeof(uint32_t);
+	udph = (struct udphdr *)((uint8_t *)iph + iphlen);
+
+	if((void *)(udph + 1) > data_end)
+		return XDP_PASS;
+
+	pd.data.src_port = udph->source;
+	pd.data.dst_port = udph->dest;
+
+	i = 0;
+	bcx = bpf_map_lookup_elem(&acl_ctx, &i);
+	if (bcx == NULL)
+		return XDP_PASS;
+
+	for (i = 0; i != DIM(data_ofs); i++) {
+		
+		input = pd.raw[data_ofs[i]];
+		if (i == 0)
+			idx = bcx->trie[0].root_index + input;
+		else
+			idx = resolve_next_index(trans, input);
+
+		val = bpf_map_lookup_elem(&acl_trans, &idx);
+		if (val == NULL)
+			return XDP_PASS;
+
+		trans = *val;
+
+		/* if match is found */
+		if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+			break;
+		}
+	}
+
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/app/acl-bpf/xdp_acl2.c b/app/acl-bpf/xdp_acl2.c
new file mode 100644
index 0000000000..c22966b01c
--- /dev/null
+++ b/app/acl-bpf/xdp_acl2.c
@@ -0,0 +1,288 @@
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/udp.h>
+#include <linux/tcp.h>
+
+#include <limits.h>
+#include <stdint.h>
+#include "acl_bpf.h"
+
+/*
+ * !!! copy of all defines - to remove
+ */
+
+/** Mask value of type "tp" for the first "ln" bit set. */
+#define RTE_LEN2MASK(ln, tp)    \
+	((tp)((uint64_t)-1 >> (sizeof(uint64_t) * CHAR_BIT - (ln))))
+
+enum {
+        RTE_ACL_TYPE_SHIFT = 29,
+        RTE_ACL_MAX_INDEX = RTE_LEN2MASK(RTE_ACL_TYPE_SHIFT, uint32_t),
+        RTE_ACL_MAX_PRIORITY = RTE_ACL_MAX_INDEX,
+        RTE_ACL_MIN_PRIORITY = 1,
+};
+
+#define RTE_ACL_NODE_DFA	(0 << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_SINGLE	(1U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_QRANGE	(3U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_MATCH	(4U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_TYPE	(7U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_UNDEFINED	UINT32_MAX
+
+#define RTE_ACL_QUAD_MAX	5
+#define RTE_ACL_QUAD_SIZE	4
+#define RTE_ACL_QUAD_SINGLE	UINT64_C(0x7f7f7f7f00000000)
+
+#define RTE_ACL_SINGLE_TRIE_SIZE	2000
+
+#define RTE_ACL_DFA_MAX		UINT8_MAX
+#define RTE_ACL_DFA_SIZE	(UINT8_MAX + 1)
+
+#define RTE_ACL_DFA_GR64_SIZE	64
+#define RTE_ACL_DFA_GR64_NUM	(RTE_ACL_DFA_SIZE / RTE_ACL_DFA_GR64_SIZE)
+#define RTE_ACL_DFA_GR64_BIT	\
+	(CHAR_BIT * sizeof(uint32_t) / RTE_ACL_DFA_GR64_NUM)
+
+#define RTE_ACL_NODE_INDEX	((uint32_t)~RTE_ACL_NODE_TYPE)
+
+#define SCALAR_QRANGE_MULT	0x01010101
+#define SCALAR_QRANGE_MASK	0x7f7f7f7f
+#define SCALAR_QRANGE_MIN	0x80808080
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, struct rte_acl_bpf_ctx);
+        __uint(max_entries, 1);
+} acl_ctx SEC(".maps");
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, uint64_t);
+        __uint(max_entries, 0x400000);
+} acl_trans SEC(".maps");
+
+struct packet_field {
+	uint8_t proto;
+	uint32_t src_ip;
+	uint32_t dst_ip;
+	uint16_t src_port;
+	uint16_t dst_port;
+};
+
+union packet_data {
+	struct packet_field data;
+	uint8_t raw[sizeof(struct packet_field)];
+};
+
+const uint32_t data_ofs[] = {
+	offsetof(struct packet_field, proto),
+	offsetof(struct packet_field, src_ip),
+	offsetof(struct packet_field, src_ip) + 1,
+	offsetof(struct packet_field, src_ip) + 2,
+	offsetof(struct packet_field, src_ip) + 3,
+	offsetof(struct packet_field, dst_ip),
+	offsetof(struct packet_field, dst_ip) + 1,
+	offsetof(struct packet_field, dst_ip) + 2,
+	offsetof(struct packet_field, dst_ip) + 3,
+	offsetof(struct packet_field, src_port),
+	offsetof(struct packet_field, src_port) + 1,
+	offsetof(struct packet_field, dst_port),
+	offsetof(struct packet_field, dst_port) + 1,
+};
+
+#define DIM(a)	(sizeof(a) / sizeof(a[0]))
+
+static void *
+resolve_match(uint32_t match_index, uint64_t trans)
+{
+	uint32_t idx;
+
+	trans &= RTE_ACL_NODE_INDEX;
+	idx = match_index + trans;
+
+	/* get match record */
+	return bpf_map_lookup_elem(&acl_trans, &idx);
+}
+
+static inline uint32_t
+scan_forward(uint32_t input, uint32_t max)
+{
+	return (input == 0) ? max : __builtin_ctz(input);
+}
+
+static uint32_t
+resolve_next_index(uint64_t transition, uint8_t input)
+{
+	uint32_t addr, index, ranges, x, a, b, c;
+
+	/* break transition into component parts */
+	ranges = transition >> (sizeof(index) * CHAR_BIT);
+	index = transition & ~RTE_ACL_NODE_INDEX;
+	addr = transition ^ index;
+
+	if (index != RTE_ACL_NODE_DFA) {
+		/* calc address for a QRANGE/SINGLE node */
+		c = (uint32_t)input * SCALAR_QRANGE_MULT;
+		a = ranges | SCALAR_QRANGE_MIN;
+		a -= (c & SCALAR_QRANGE_MASK);
+		b = c & SCALAR_QRANGE_MIN;
+		a &= SCALAR_QRANGE_MIN;
+		a ^= (ranges ^ b) & (a ^ b);
+		x = scan_forward(a, 32) >> 3;
+	} else {
+		/* calc address for a DFA node */
+		x = ranges >> (input /
+			RTE_ACL_DFA_GR64_SIZE * RTE_ACL_DFA_GR64_BIT);
+		x &= UINT8_MAX;
+		x = input - x;
+	}
+
+	addr += x;
+	return addr;
+}
+
+static inline int
+one_step_trans(uint32_t match_index, uint8_t input, uint64_t trans,
+	uint64_t *next) 
+{
+	uint32_t idx;
+	const uint64_t *val;
+
+	idx = resolve_next_index(trans, input);
+	val = bpf_map_lookup_elem(&acl_trans, &idx);
+	if (val == NULL)
+		return XDP_PASS;
+	trans = *val;
+	/* if match is found */
+	if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+		val = resolve_match(match_index, trans);
+		if (val == NULL)
+			return XDP_PASS;
+		return XDP_DROP;
+	}
+	*next = trans;
+	return XDP_ABORTED;
+}
+
+
+SEC("xdp_prog")
+int xdp_acl_prog1(struct xdp_md *ctx)
+{
+	void *data_end;
+	void *data;
+	int32_t rc;
+	uint32_t i, idx, input, iphlen, match_index;
+	uint64_t trans;
+	const uint64_t *val;
+	struct ethhdr *eth;
+	struct iphdr *iph;
+	struct udphdr *udph;
+	union packet_data pd;
+	const struct rte_acl_bpf_ctx *bcx;
+
+	data_end = (void *)(long)ctx->data_end;
+	data = (void *)(long)ctx->data;
+
+	eth = data;
+	if (data + sizeof(*eth) > data_end)
+        	return XDP_DROP;
+
+	if (eth->h_proto != htons(ETH_P_IP))
+		return XDP_PASS;
+
+	iph = (struct iphdr *)(eth + 1);
+	if ((void *)(iph + 1) > data_end)
+		return XDP_DROP;
+
+	pd.data.proto = iph->protocol;
+	pd.data.src_ip = iph->saddr;
+	pd.data.dst_ip = iph->daddr;
+
+	iphlen = iph->ihl * sizeof(uint32_t);
+	udph = (struct udphdr *)((uint8_t *)iph + iphlen);
+
+	if((void *)(udph + 1) > data_end)
+		return XDP_PASS;
+
+	pd.data.src_port = udph->source;
+	pd.data.dst_port = udph->dest;
+
+	i = 0;
+	bcx = bpf_map_lookup_elem(&acl_ctx, &i);
+	if (bcx == NULL)
+		return XDP_PASS;
+
+	match_index = bcx->match_index;
+
+	input = pd.data.proto;
+	idx = bcx->trie[0].root_index + input;
+	val = bpf_map_lookup_elem(&acl_trans, &idx);
+	if (val == NULL)
+		return XDP_PASS;
+	trans = *val;
+	/* if match is found */
+	if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+		val = resolve_match(match_index, trans);
+		if (val == NULL)
+			return XDP_PASS;
+		return XDP_DROP;
+	}
+
+	rc = one_step_trans(match_index, pd.raw[4], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[5], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[6], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[7], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[8], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[9], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[10], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[11], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[12], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[13], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[14], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[15], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/app/acl-bpf/xdp_acl3.c b/app/acl-bpf/xdp_acl3.c
new file mode 100644
index 0000000000..d6b50caf61
--- /dev/null
+++ b/app/acl-bpf/xdp_acl3.c
@@ -0,0 +1,289 @@
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/udp.h>
+#include <linux/tcp.h>
+
+#include <limits.h>
+#include <stdint.h>
+#include "acl_bpf.h"
+
+/*
+ * !!! copy of all defines - to remove
+ */
+
+/** Mask value of type "tp" for the first "ln" bit set. */
+#define RTE_LEN2MASK(ln, tp)    \
+	((tp)((uint64_t)-1 >> (sizeof(uint64_t) * CHAR_BIT - (ln))))
+
+enum {
+        RTE_ACL_TYPE_SHIFT = 29,
+        RTE_ACL_MAX_INDEX = RTE_LEN2MASK(RTE_ACL_TYPE_SHIFT, uint32_t),
+        RTE_ACL_MAX_PRIORITY = RTE_ACL_MAX_INDEX,
+        RTE_ACL_MIN_PRIORITY = 1,
+};
+
+#define RTE_ACL_NODE_DFA	(0 << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_SINGLE	(1U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_QRANGE	(3U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_MATCH	(4U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_TYPE	(7U << RTE_ACL_TYPE_SHIFT)
+#define RTE_ACL_NODE_UNDEFINED	UINT32_MAX
+
+#define RTE_ACL_QUAD_MAX	5
+#define RTE_ACL_QUAD_SIZE	4
+#define RTE_ACL_QUAD_SINGLE	UINT64_C(0x7f7f7f7f00000000)
+
+#define RTE_ACL_SINGLE_TRIE_SIZE	2000
+
+#define RTE_ACL_DFA_MAX		UINT8_MAX
+#define RTE_ACL_DFA_SIZE	(UINT8_MAX + 1)
+
+#define RTE_ACL_DFA_GR64_SIZE	64
+#define RTE_ACL_DFA_GR64_NUM	(RTE_ACL_DFA_SIZE / RTE_ACL_DFA_GR64_SIZE)
+#define RTE_ACL_DFA_GR64_BIT	\
+	(CHAR_BIT * sizeof(uint32_t) / RTE_ACL_DFA_GR64_NUM)
+
+#define RTE_ACL_NODE_INDEX	((uint32_t)~RTE_ACL_NODE_TYPE)
+
+#define SCALAR_QRANGE_MULT	0x01010101
+#define SCALAR_QRANGE_MASK	0x7f7f7f7f
+#define SCALAR_QRANGE_MIN	0x80808080
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, struct rte_acl_bpf_ctx);
+        __uint(max_entries, 1);
+} acl_ctx SEC(".maps");
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, uint64_t);
+        __uint(max_entries, 0x400000);
+} acl_trans SEC(".maps");
+
+struct packet_field {
+	uint8_t proto;
+	uint32_t src_ip;
+	uint32_t dst_ip;
+	uint16_t src_port;
+	uint16_t dst_port;
+};
+
+union packet_data {
+	struct packet_field data;
+	uint8_t raw[sizeof(struct packet_field)];
+};
+
+const uint32_t data_ofs[] = {
+	offsetof(struct packet_field, proto),
+	offsetof(struct packet_field, src_ip),
+	offsetof(struct packet_field, src_ip) + 1,
+	offsetof(struct packet_field, src_ip) + 2,
+	offsetof(struct packet_field, src_ip) + 3,
+	offsetof(struct packet_field, dst_ip),
+	offsetof(struct packet_field, dst_ip) + 1,
+	offsetof(struct packet_field, dst_ip) + 2,
+	offsetof(struct packet_field, dst_ip) + 3,
+	offsetof(struct packet_field, src_port),
+	offsetof(struct packet_field, src_port) + 1,
+	offsetof(struct packet_field, dst_port),
+	offsetof(struct packet_field, dst_port) + 1,
+};
+
+#define DIM(a)	(sizeof(a) / sizeof(a[0]))
+
+static void *
+resolve_match(uint32_t match_index, uint64_t trans)
+{
+	uint32_t idx;
+
+	trans &= RTE_ACL_NODE_INDEX;
+	idx = match_index + trans;
+
+	/* get match record */
+	return bpf_map_lookup_elem(&acl_trans, &idx);
+}
+
+static inline uint32_t
+scan_forward(uint32_t input, uint32_t max)
+{
+	return (input == 0) ? max : __builtin_ctz(input);
+}
+
+static uint32_t
+resolve_next_index(uint64_t transition, uint8_t input)
+{
+	uint32_t addr, index, ranges, x, a, b, c;
+
+	/* break transition into component parts */
+	ranges = transition >> (sizeof(index) * CHAR_BIT);
+	index = transition & ~RTE_ACL_NODE_INDEX;
+	addr = transition ^ index;
+
+	if (index != RTE_ACL_NODE_DFA) {
+		/* calc address for a QRANGE/SINGLE node */
+		c = (uint32_t)input * SCALAR_QRANGE_MULT;
+		a = ranges | SCALAR_QRANGE_MIN;
+		a -= (c & SCALAR_QRANGE_MASK);
+		b = c & SCALAR_QRANGE_MIN;
+		a &= SCALAR_QRANGE_MIN;
+		a ^= (ranges ^ b) & (a ^ b);
+		x = scan_forward(a, 32) >> 3;
+	} else {
+		/* calc address for a DFA node */
+		x = ranges >> (input /
+			RTE_ACL_DFA_GR64_SIZE * RTE_ACL_DFA_GR64_BIT);
+		x &= UINT8_MAX;
+		x = input - x;
+	}
+
+	addr += x;
+	return addr;
+}
+
+static inline int
+one_step_trans(uint32_t match_index, uint8_t input, uint64_t trans,
+	uint64_t *next) 
+{
+	uint32_t idx;
+	const uint64_t *val;
+
+	idx = resolve_next_index(trans, input);
+	val = bpf_map_lookup_elem(&acl_trans, &idx);
+	if (val == NULL)
+		return XDP_PASS;
+	trans = *val;
+	/* if match is found */
+	if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+		val = resolve_match(match_index, trans);
+		if (val == NULL)
+			return XDP_PASS;
+		//bpf_printk("%s:%d *val=%#lx\n", __func__, __LINE__, *val);
+		return (*val == 0) ? XDP_PASS : XDP_DROP;
+	}
+	*next = trans;
+	return XDP_ABORTED;
+}
+
+
+SEC("xdp_prog")
+int xdp_acl_prog1(struct xdp_md *ctx)
+{
+	void *data_end;
+	void *data;
+	int32_t rc;
+	uint32_t i, idx, input, iphlen, match_index;
+	uint64_t trans;
+	const uint64_t *val;
+	struct ethhdr *eth;
+	struct iphdr *iph;
+	struct udphdr *udph;
+	union packet_data pd;
+	const struct rte_acl_bpf_ctx *bcx;
+
+	data_end = (void *)(long)ctx->data_end;
+	data = (void *)(long)ctx->data;
+
+	eth = data;
+	if (data + sizeof(*eth) > data_end)
+        	return XDP_DROP;
+
+	if (eth->h_proto != htons(ETH_P_IP))
+		return XDP_PASS;
+
+	iph = (struct iphdr *)(eth + 1);
+	if ((void *)(iph + 1) > data_end)
+		return XDP_DROP;
+
+	pd.data.proto = iph->protocol;
+	pd.data.src_ip = iph->saddr;
+	pd.data.dst_ip = iph->daddr;
+
+	iphlen = iph->ihl * sizeof(uint32_t);
+	udph = (struct udphdr *)((uint8_t *)iph + iphlen);
+
+	if((void *)(udph + 1) > data_end)
+		return XDP_PASS;
+
+	pd.data.src_port = udph->source;
+	pd.data.dst_port = udph->dest;
+
+	i = 0;
+	bcx = bpf_map_lookup_elem(&acl_ctx, &i);
+	if (bcx == NULL)
+		return XDP_PASS;
+
+	match_index = bcx->match_index;
+
+	input = pd.data.proto;
+	idx = bcx->trie[0].root_index + input;
+	val = bpf_map_lookup_elem(&acl_trans, &idx);
+	if (val == NULL)
+		return XDP_PASS;
+	trans = *val;
+	/* if match is found */
+	if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+		val = resolve_match(match_index, trans);
+		if (val == NULL)
+			return XDP_PASS;
+		return XDP_DROP;
+	}
+
+	rc = one_step_trans(match_index, pd.raw[4], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[5], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[6], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[7], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[8], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[9], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[10], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[11], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[12], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[13], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[14], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[15], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/app/acl-bpf/xdp_acl4.c b/app/acl-bpf/xdp_acl4.c
new file mode 100644
index 0000000000..fec37233be
--- /dev/null
+++ b/app/acl-bpf/xdp_acl4.c
@@ -0,0 +1,257 @@
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+#include <linux/ip.h>
+#include <linux/ipv6.h>
+#include <linux/udp.h>
+#include <linux/tcp.h>
+
+#include <limits.h>
+#include <stdint.h>
+#include "acl_bpf.h"
+#include "acl_internal.h"
+#include "acl_xdp.h"
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, struct rte_acl_bpf_ctx);
+        __uint(max_entries, 1);
+} acl_ctx SEC(".maps");
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, uint64_t);
+        __uint(max_entries, 0x400000);
+} acl_trans SEC(".maps");
+
+struct {
+        __uint(type, BPF_MAP_TYPE_ARRAY);
+        __type(key, uint32_t);
+        __type(value, struct ipv4_rule);
+        __uint(max_entries, 0x10000);
+} acl_rule SEC(".maps");
+
+
+union packet_data {
+	struct ipv4_5tuple data;
+	uint8_t raw[sizeof(struct ipv4_5tuple)];
+};
+
+#define DIM(a)	(sizeof(a) / sizeof(a[0]))
+
+static enum xdp_action
+resolve_match(uint32_t match_index, uint64_t trans)
+{
+	uint32_t idx;
+	union rte_acl_bpf_match *match;
+	struct ipv4_rule *rule;
+
+	trans &= RTE_ACL_NODE_INDEX;
+	idx = match_index + trans;
+
+	/* get match record */
+	match = bpf_map_lookup_elem(&acl_trans, &idx);
+	if (match == NULL) {
+		return XDP_PASS;
+	}
+
+	/* find corresponding rule record */
+	idx = match->result;
+	//bpf_printk("%s:%d *idx=%u\n", __func__, __LINE__, idx);
+	rule = bpf_map_lookup_elem(&acl_rule, &idx);
+	if (rule == NULL)
+		return XDP_PASS;
+
+	/* update rule stats */
+	__atomic_fetch_add(&rule->num_packet, 1, __ATOMIC_RELAXED);
+
+	return rule->action;
+}
+
+static inline uint32_t
+scan_forward(uint32_t input, uint32_t max)
+{
+	return (input == 0) ? max : __builtin_ctz(input);
+}
+
+static uint32_t
+resolve_next_index(uint64_t transition, uint8_t input)
+{
+	uint32_t addr, index, ranges, x, a, b, c;
+
+	/* break transition into component parts */
+	ranges = transition >> (sizeof(index) * CHAR_BIT);
+	index = transition & ~RTE_ACL_NODE_INDEX;
+	addr = transition ^ index;
+
+	if (index != RTE_ACL_NODE_DFA) {
+		/* calc address for a QRANGE/SINGLE node */
+		c = (uint32_t)input * SCALAR_QRANGE_MULT;
+		a = ranges | SCALAR_QRANGE_MIN;
+		a -= (c & SCALAR_QRANGE_MASK);
+		b = c & SCALAR_QRANGE_MIN;
+		a &= SCALAR_QRANGE_MIN;
+		a ^= (ranges ^ b) & (a ^ b);
+		x = scan_forward(a, 32) >> 3;
+	} else {
+		/* calc address for a DFA node */
+		x = ranges >> (input /
+			RTE_ACL_DFA_GR64_SIZE * RTE_ACL_DFA_GR64_BIT);
+		x &= UINT8_MAX;
+		x = input - x;
+	}
+
+	addr += x;
+	return addr;
+}
+
+static inline int
+one_step_trans(uint32_t match_index, uint8_t input, uint64_t trans,
+	uint64_t *next) 
+{
+	uint32_t idx;
+	enum xdp_action action;
+	const uint64_t *val;
+
+	idx = resolve_next_index(trans, input);
+	val = bpf_map_lookup_elem(&acl_trans, &idx);
+	if (val == NULL)
+		return XDP_PASS;
+	trans = *val;
+	/* if match is found */
+	if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+		action = resolve_match(match_index, trans);
+		//bpf_printk("%s:%d *action=%d\n", __func__, __LINE__, action);
+		return action;
+	}
+	*next = trans;
+	return XDP_ABORTED;
+}
+
+
+SEC("xdp_prog")
+int xdp_acl_prog1(struct xdp_md *ctx)
+{
+	void *data_end;
+	void *data;
+	int32_t rc;
+	enum xdp_action action;
+	uint32_t i, idx, input, iphlen, match_index, ofs;
+	uint64_t trans;
+	const uint64_t *val;
+	struct ethhdr *eth;
+	struct iphdr *iph;
+	struct udphdr *udph;
+	union packet_data pd;
+	const struct rte_acl_bpf_ctx *bcx;
+
+	data_end = (void *)(long)ctx->data_end;
+	data = (void *)(long)ctx->data;
+
+	eth = data;
+	if (data + sizeof(*eth) > data_end)
+        	return XDP_DROP;
+
+	if (eth->h_proto != htons(ETH_P_IP))
+		return XDP_PASS;
+
+	iph = (struct iphdr *)(eth + 1);
+	if ((void *)(iph + 1) > data_end)
+		return XDP_DROP;
+
+	pd.data.proto = iph->protocol;
+	pd.data.ip_src = iph->saddr;
+	pd.data.ip_dst = iph->daddr;
+
+	iphlen = iph->ihl * sizeof(uint32_t);
+	udph = (struct udphdr *)((uint8_t *)iph + iphlen);
+
+	if((void *)(udph + 1) > data_end)
+		return XDP_PASS;
+
+	pd.data.port_src = udph->source;
+	pd.data.port_dst = udph->dest;
+
+	/* start search with IP proto */
+	i = 0;
+	bcx = bpf_map_lookup_elem(&acl_ctx, &i);
+	if (bcx == NULL)
+		return XDP_PASS;
+
+	match_index = bcx->match_index;
+
+	input = pd.data.proto;
+	idx = bcx->trie[0].root_index + input;
+	val = bpf_map_lookup_elem(&acl_trans, &idx);
+	if (val == NULL)
+		return XDP_PASS;
+	trans = *val;
+	/* if match is found */
+	if ((trans & RTE_ACL_NODE_MATCH) != 0) {
+		action = resolve_match(match_index, trans);
+		return action;
+	}
+
+	/* continue search with IP src addr */
+	ofs = offsetof(struct ipv4_5tuple, ip_src);
+	rc = one_step_trans(match_index, pd.raw[ofs], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[ofs + 1], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[ofs + 2], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[ofs + 3], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	/* continue search with IP dest addr */
+	ofs = offsetof(struct ipv4_5tuple, ip_dst);
+	rc = one_step_trans(match_index, pd.raw[ofs], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[ofs + 1], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[ofs + 2], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[ofs + 3], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	/* continue search with L4 src port number */
+	ofs = offsetof(struct ipv4_5tuple, port_src);
+	rc = one_step_trans(match_index, pd.raw[ofs], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[ofs + 1], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	/* continue search with L4 dest port number */
+	ofs = offsetof(struct ipv4_5tuple, port_dst);
+	rc = one_step_trans(match_index, pd.raw[ofs], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+
+	rc = one_step_trans(match_index, pd.raw[ofs + 1], trans, &trans); 
+	if (rc != XDP_ABORTED)
+		return rc;
+	
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/app/acl-bpf/xdp_prog1.c b/app/acl-bpf/xdp_prog1.c
new file mode 100644
index 0000000000..d192a425a9
--- /dev/null
+++ b/app/acl-bpf/xdp_prog1.c
@@ -0,0 +1,39 @@
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+
+struct {
+        __uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+        __type(key, uint32_t);
+        __type(value, uint64_t);
+        __uint(max_entries, 1);
+} rxcnt SEC(".maps");
+
+
+SEC("xdp_prog")
+int xdp_prog1(struct xdp_md *ctx)
+{
+	void *data_end = (void *)(long)ctx->data_end;
+	void *data = (void *)(long)ctx->data;
+	struct ethhdr *eth = data;
+	uint16_t h_proto;
+	uint32_t key;
+	uint64_t *val;
+
+	if (data + sizeof(struct ethhdr) > data_end)
+        	return XDP_DROP;
+
+	h_proto = eth->h_proto;
+
+	if (h_proto == htons(ETH_P_IPV6)) {
+		key = 0;
+		val = bpf_map_lookup_elem(&rxcnt, &key);
+		if (val != NULL)
+			*val += 1;
+	}
+
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/app/acl-bpf/xdp_timer1.c b/app/acl-bpf/xdp_timer1.c
new file mode 100644
index 0000000000..89b40140cc
--- /dev/null
+++ b/app/acl-bpf/xdp_timer1.c
@@ -0,0 +1,69 @@
+#include <time.h>
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+
+struct rxcnt_elem {
+	uint64_t val;
+	struct bpf_timer timer;
+};
+
+struct {
+        __uint(type, BPF_MAP_TYPE_HASH);
+        __type(key, uint32_t);
+        __type(value, struct rxcnt_elem);
+        __uint(max_entries, 1);
+} rxcnt SEC(".maps");
+
+struct hmap_elem {
+	int counter;
+	struct bpf_timer timer;
+	//struct bpf_timer timer2;
+	struct bpf_spin_lock lock; /* unused */
+};
+
+struct {
+        __uint(type, BPF_MAP_TYPE_HASH);
+        __type(key, uint32_t);
+        __type(value, struct hmap_elem);
+        __uint(max_entries, 0x1000);
+} rxhash SEC(".maps");
+
+
+SEC("xdp_prog")
+int xdp_prog1(struct xdp_md *ctx)
+{
+	void *data_end = (void *)(long)ctx->data_end;
+	void *data = (void *)(long)ctx->data;
+	struct ethhdr *eth = data;
+	uint16_t h_proto;
+	uint32_t key;
+	struct rxcnt_elem *val;
+	struct hmap_elem *hme;
+
+	if (data + sizeof(struct ethhdr) > data_end)
+        	return XDP_DROP;
+
+	h_proto = eth->h_proto;
+
+	if (h_proto == htons(ETH_P_IPV6)) {
+		key = 0;
+		val = bpf_map_lookup_elem(&rxcnt, &key);
+		if (val != NULL) {
+			val->val += 1;
+			bpf_timer_init(&val->timer, &rxcnt, CLOCK_BOOTTIME);
+		}
+		key = h_proto + ((uint32_t *)data)[0];
+		hme = bpf_map_lookup_elem(&rxhash, &key);
+		if (hme != NULL) {
+			hme->counter = 0;
+			bpf_timer_init(&hme->timer, &rxhash, CLOCK_BOOTTIME);
+			//bpf_timer_init(&hme->timer, &rxcnt, CLOCK_MONOTONIC);
+		}
+	}
+
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/app/meson.build b/app/meson.build
index 1798db3ae4..b80e31272f 100644
--- a/app/meson.build
+++ b/app/meson.build
@@ -13,6 +13,7 @@ if enable_apps.length() == 0
 endif
 
 apps = [
+        'acl-bpf',
         'dumpcap',
         'graph',
         'pdump',
diff --git a/app/test-acl/main.c b/app/test-acl/main.c
index bbf2ec5b63..3a791b3ccf 100644
--- a/app/test-acl/main.c
+++ b/app/test-acl/main.c
@@ -6,7 +6,6 @@
 #include <rte_acl.h>
 #include <getopt.h>
 #include <string.h>
-#include <unistd.h>
 
 #include <rte_cycles.h>
 #include <rte_per_lcore.h>
@@ -42,7 +41,6 @@
 #define	OPT_ITER_NUM		"iter"
 #define	OPT_VERBOSE		"verbose"
 #define	OPT_IPV6		"ipv6"
-#define	OPT_BPF			"bpf"
 
 #define	TRACE_DEFAULT_NUM	0x10000
 #define	TRACE_STEP_MAX		0x1000
@@ -101,17 +99,6 @@ static const struct acl_alg acl_alg[] = {
 	},
 };
 
-enum bpf_opt {
-	BPF_DISABLED = 0,
-	BPF_TEST = 1,
-	BPF_FILL = 2,
-};
-
-struct bpf_conf {	
-	enum bpf_opt opt;
-	struct rte_acl_bpf bpx;
-};
-
 static struct {
 	const char         *prgname;
 	const char         *rule_file;
@@ -130,7 +117,6 @@ static struct {
 	uint32_t            used_traces;
 	void               *traces;
 	struct rte_acl_ctx *acx;
-	struct bpf_conf bpf;
 } config = {
 	.bld_categories = 3,
 	.run_categories = 1,
@@ -144,7 +130,6 @@ static struct {
 		.alg = RTE_ACL_CLASSIFY_DEFAULT,
 	},
 	.ipv6 = IPV6_FRMT_NONE,
-	.bpf.opt = BPF_DISABLED,
 };
 
 static struct rte_acl_param prm = {
@@ -970,35 +955,6 @@ add_cb_rules(FILE *f, struct rte_acl_ctx *ctx)
 	return 0;
 }
 
-static void
-print_bpf_conf(const struct bpf_conf *cfg)
-{
-	printf("bpf_onf={\n");
-	printf("\topt=%d,\n", cfg->opt);
-	printf("\tctx_fd=%u,\n", cfg->bpx.ctx_fd);
-	printf("\ttrans_fd=%u,\n", cfg->bpx.trans_fd);
-	printf("}\n");
-
-#if 0
-	printf("bpf_ctx={\n");
-	printf("\tnum_trans=%u,\n", bcx->num_trans);
-	printf("\tmatch_index=%u,\n", bcx->match_index);
-	printf("\tnum_matches=%u,\n", bcx->num_matches);
-	printf("\tnum_tries=%u,\n", bcx->num_tries);
-	for (i = 0; i != bcx->num_tries; i++) {
-		printf("\ttrie[%u]={\n", i);
-		printf("\t\troot_index=%u,\n", bcx->trie[i].root_index);
-		printf("\t\tnum_offset=%u,\n", bcx->trie[i].num_offset);
-		printf("\t\tdata_offset={\n\t\t\t");
-		for (j = 0; j != bcx->trie[i].num_offset; j++)
-			printf(" %u,", bcx->trie[i].data_offset[j]); 
-		printf("\n\t\t},\n");
-		printf("\t},\n");
-	};
-	printf("}\n");
-#endif
-}
-
 static void
 acx_init(void)
 {
@@ -1059,14 +1015,6 @@ acx_init(void)
 
 	rte_acl_dump(config.acx);
 
-	if (ret == 0) {
-		if (config.bpf.opt == BPF_TEST)
-			ret = rte_acl_bpf_init(&config.bpf.bpx, config.acx);
-		else if (config.bpf.opt == BPF_FILL)
-			ret = rte_acl_bpf_fill(&config.bpf.bpx, config.acx);
-		print_bpf_conf(&config.bpf);
-	}
-
 	if (ret != 0)
 		rte_exit(ret, "failed to build search context\n");
 }
@@ -1089,16 +1037,8 @@ search_ip5tuples_once(uint32_t categories, uint32_t step, const char *alg)
 			v += config.trace_sz;
 		}
 
-		if (config.bpf.opt == BPF_DISABLED)
-			ret = rte_acl_classify(config.acx, data, results,
-				n, categories);
-		else if (config.bpf.opt == BPF_TEST) {
-			ret = 0;
-			for (j = 0; j != n && ret == 0; j++)
-				ret = rte_acl_bpf_classify(&config.bpf.bpx,
-					data[j], config.trace_sz, results + j);
-		} else
-			ret = 0;
+		ret = rte_acl_classify(config.acx, data, results,
+			n, categories);
 
 		if (ret != 0)
 			rte_exit(ret, "classify for ipv%c_5tuples returns %d\n",
@@ -1182,34 +1122,6 @@ get_alg_opt(const char *opt, const char *name)
 		opt, name);
 }
 
-static int
-get_bpf_ids(struct bpf_conf *bpf, const char *opt)
-{
-	bpf->opt = BPF_FILL;
-	GET_CB_FIELD(opt, bpf->bpx.ctx_fd, 0, UINT32_MAX, ':');
-	GET_CB_FIELD(opt, bpf->bpx.trans_fd, 0, UINT32_MAX, 0);
-	return 0;
-}
-
-static void
-get_bpf_opt(struct bpf_conf *bpf, const char *opt, const char *name)
-{
-	int32_t rc;
-
-	memset(bpf, 0, sizeof(*bpf));
-
-	rc = -EINVAL;
-	if (strcmp(opt, "test") == 0) {
-		bpf->opt = BPF_TEST;
-		rc = 0;
-	} else {
-		rc = get_bpf_ids(bpf, opt);
-	}
-	if (rc != 0)
-		rte_exit(rc, "invalid value: \"%s\" for option: %s\n",
-			opt, name);
-}
-
 static void
 get_ipv6_opt(const char *opt, const char *name)
 {
@@ -1282,8 +1194,7 @@ print_usage(const char *prgname)
 		"[--" OPT_ITER_NUM "=<number of iterations to perform>]\n"
 		"[--" OPT_VERBOSE "=<verbose level>]\n"
 		"[--" OPT_SEARCH_ALG "=%s]\n"
-		"[--" OPT_IPV6 "(=4B | 8B) <IPv6 rules and trace files>]\n"
-		"[--" OPT_BPF "(=test | <ictx_map_id:trans_map_id>)\n",
+		"[--" OPT_IPV6 "(=4B | 8B) <IPv6 rules and trace files>]\n",
 		prgname, RTE_ACL_RESULTS_MULTIPLIER,
 		(uint32_t)RTE_ACL_MAX_CATEGORIES,
 		buf);
@@ -1306,7 +1217,6 @@ dump_config(FILE *f)
 	fprintf(f, "%s:%u(%s)\n", OPT_SEARCH_ALG, config.alg.alg,
 		config.alg.name);
 	fprintf(f, "%s:%u\n", OPT_IPV6, config.ipv6);
-	fprintf(f, "%s:%u\n", OPT_BPF, config.bpf.opt);
 }
 
 static void
@@ -1336,7 +1246,6 @@ get_input_opts(int argc, char **argv)
 		{OPT_VERBOSE, 1, 0, 0},
 		{OPT_SEARCH_ALG, 1, 0, 0},
 		{OPT_IPV6, 2, 0, 0},
-		{OPT_BPF, 1, 0, 0},
 		{NULL, 0, 0, 0}
 	};
 
@@ -1388,8 +1297,6 @@ get_input_opts(int argc, char **argv)
 			config.ipv6 = IPV6_FRMT_U32;
 			if (optarg != NULL)
 				get_ipv6_opt(optarg, lgopts[opt_idx].name);
-		} else if (strcmp(lgopts[opt_idx].name, OPT_BPF) == 0) {
-			get_bpf_opt(&config.bpf, optarg, lgopts[opt_idx].name);
 		}
 	}
 	config.trace_sz = config.ipv6 ? sizeof(struct ipv6_5tuple) :
@@ -1428,8 +1335,6 @@ main(int argc, char **argv)
 
 	rte_eal_mp_wait_lcore();
 
-	if (config.bpf.opt == BPF_TEST)
-		rte_acl_bpf_fini(&config.bpf.bpx);
 	rte_acl_free(config.acx);
 	return 0;
 }
diff --git a/app/test-acl/xdp_timer1.c b/app/test-acl/xdp_timer1.c
new file mode 100644
index 0000000000..89b40140cc
--- /dev/null
+++ b/app/test-acl/xdp_timer1.c
@@ -0,0 +1,69 @@
+#include <time.h>
+#include <linux/bpf.h>
+#include <bpf/bpf_helpers.h>
+#include <linux/if_ether.h>
+#include <arpa/inet.h>
+
+struct rxcnt_elem {
+	uint64_t val;
+	struct bpf_timer timer;
+};
+
+struct {
+        __uint(type, BPF_MAP_TYPE_HASH);
+        __type(key, uint32_t);
+        __type(value, struct rxcnt_elem);
+        __uint(max_entries, 1);
+} rxcnt SEC(".maps");
+
+struct hmap_elem {
+	int counter;
+	struct bpf_timer timer;
+	//struct bpf_timer timer2;
+	struct bpf_spin_lock lock; /* unused */
+};
+
+struct {
+        __uint(type, BPF_MAP_TYPE_HASH);
+        __type(key, uint32_t);
+        __type(value, struct hmap_elem);
+        __uint(max_entries, 0x1000);
+} rxhash SEC(".maps");
+
+
+SEC("xdp_prog")
+int xdp_prog1(struct xdp_md *ctx)
+{
+	void *data_end = (void *)(long)ctx->data_end;
+	void *data = (void *)(long)ctx->data;
+	struct ethhdr *eth = data;
+	uint16_t h_proto;
+	uint32_t key;
+	struct rxcnt_elem *val;
+	struct hmap_elem *hme;
+
+	if (data + sizeof(struct ethhdr) > data_end)
+        	return XDP_DROP;
+
+	h_proto = eth->h_proto;
+
+	if (h_proto == htons(ETH_P_IPV6)) {
+		key = 0;
+		val = bpf_map_lookup_elem(&rxcnt, &key);
+		if (val != NULL) {
+			val->val += 1;
+			bpf_timer_init(&val->timer, &rxcnt, CLOCK_BOOTTIME);
+		}
+		key = h_proto + ((uint32_t *)data)[0];
+		hme = bpf_map_lookup_elem(&rxhash, &key);
+		if (hme != NULL) {
+			hme->counter = 0;
+			bpf_timer_init(&hme->timer, &rxhash, CLOCK_BOOTTIME);
+			//bpf_timer_init(&hme->timer, &rxcnt, CLOCK_MONOTONIC);
+		}
+	}
+
+	return XDP_PASS;
+}
+
+char _license[] SEC("license") = "GPL";
diff --git a/lib/acl/acl_bpf.c b/lib/acl/acl_bpf.c
index 4d262f7e43..176827e455 100644
--- a/lib/acl/acl_bpf.c
+++ b/lib/acl/acl_bpf.c
@@ -12,10 +12,11 @@
 #include <unistd.h>
 
 static void
-acl_bpf_reset(struct rte_acl_bpf *btx)
+acl_bpf_reset(struct rte_acl_bpf_fd *btx)
 {
 	btx->trans_fd = -1;
 	btx->ctx_fd = -1;
+	btx->rule_fd = -1;
 }
 
 static void
@@ -49,7 +50,7 @@ fill_bpf_ctx(struct rte_acl_bpf_ctx *btx, const struct rte_acl_ctx *ctx)
 }
 
 static int
-fill_ctx_map(const struct rte_acl_bpf *bpx,  const struct rte_acl_ctx *ctx)
+fill_ctx_map(const struct rte_acl_bpf_fd *bpx,  const struct rte_acl_ctx *ctx)
 {
 	int32_t rc;
 	uint32_t i;
@@ -69,7 +70,7 @@ fill_ctx_map(const struct rte_acl_bpf *bpx,  const struct rte_acl_ctx *ctx)
 }
 
 static int
-fill_trans_map(const struct rte_acl_bpf *bpx,  const struct rte_acl_ctx *ctx)
+fill_trans_map(const struct rte_acl_bpf_fd *bpx,  const struct rte_acl_ctx *ctx)
 {
 	int32_t rc;
 	uint32_t i, j, k;
@@ -106,96 +107,72 @@ fill_trans_map(const struct rte_acl_bpf *bpx,  const struct rte_acl_ctx *ctx)
 }
 
 int
-rte_acl_bpf_init(struct rte_acl_bpf *bpx, const struct rte_acl_ctx *ctx)
+rte_acl_bpf_open(const struct rte_acl_bpf_id *bpid, struct rte_acl_bpf_fd *bpfd)
 {
 	int32_t rc;
-	struct rte_acl_bpf_ctx btx;
-	char buf[0x100];
-
-	if (bpx == NULL || ctx == NULL)
-		return -EINVAL;
 
-	acl_bpf_reset(bpx);
-	fill_bpf_ctx(&btx, ctx);
+	/* set all file descriptors to -1 */
+	acl_bpf_reset(bpfd);
 
-	/* create CTX map */
-	snprintf(buf, sizeof(buf), "%s_ctx", ctx->name);
-	bpx->ctx_fd = bpf_map_create(BPF_MAP_TYPE_ARRAY, buf,
-		sizeof(uint32_t), sizeof(btx), 1, NULL);
-	rc = (bpx->ctx_fd < 0) ? -errno : 0;
+	bpfd->ctx_fd = bpf_map_get_fd_by_id(bpid->ctx_id);
+	rc = (bpfd->ctx_fd < 0) ? -errno : 0;
 	printf("%s:%d  "
-		"bpf_map_create(name=\"%s\", sz=%u) returns %d, errno=%d\n",
-		__func__, __LINE__, buf, 1, bpx->ctx_fd, rc);
-	if (rc != 0) {
-		rte_acl_bpf_fini(bpx);
-		return rc;
-	}
+		"bpf_map_get_fd(=\"%u\") returns %d, errno=%d\n",
+		__func__, __LINE__, bpid->ctx_id,  bpfd->ctx_fd, rc);
 
-	/* fill CTX map */
-	rc = fill_ctx_map(bpx, ctx);
-	if (rc != 0) {
-		rte_acl_bpf_fini(bpx);
-		return rc;
+	if (rc == 0) {
+		bpfd->trans_fd = bpf_map_get_fd_by_id(bpid->trans_id);
+		rc = (bpfd->trans_fd < 0) ? -errno : 0;
+		printf("%s:%d  "
+			"bpf_map_get_fd(=\"%u\") returns %d, errno=%d\n",
+			__func__, __LINE__,
+			bpid->trans_id,  bpfd->trans_fd, rc);
 	}
 
-	bpx->trans_fd = bpf_map_create(BPF_MAP_TYPE_ARRAY, buf,
-		sizeof(uint32_t), sizeof(uint64_t), btx.num_trans, NULL);
-	rc = (bpx->trans_fd < 0) ? -errno : 0;
-	printf("%s:%d  "
-		"bpf_map_create(name=\"%s\", sz=%u) returns %d, errno=%d\n",
-		__func__, __LINE__, buf, btx.num_trans, bpx->trans_fd, rc);
-	if (rc != 0) {
-		rte_acl_bpf_fini(bpx);
-		return rc;
+	if (rc == 0) {
+		bpfd->rule_fd = bpf_map_get_fd_by_id(bpid->rule_id);
+		rc = (bpfd->rule_fd < 0) ? -errno : 0;
+		printf("%s:%d  "
+			"bpf_map_get_fd(=\"%u\") returns %d, errno=%d\n",
+			__func__, __LINE__,
+			bpid->rule_id,  bpfd->rule_fd, rc);
 	}
 
-	/* fill TRANS map */
-	rc = fill_trans_map(bpx, ctx);
-	if (rc != 0) {
-		rte_acl_bpf_fini(bpx);
-		return rc;
-	}
+	/* success */
+	if (rc == 0)
+		return 0;
 
-	return 0;
+	rte_acl_bpf_close(bpfd);
+	return rc;
 }
 
 int
-rte_acl_bpf_fill(const struct rte_acl_bpf *bpid, const struct rte_acl_ctx *ctx)
+rte_acl_bpf_fill(const struct rte_acl_bpf_fd *bpfd,
+	const struct rte_acl_ctx *ctx)
 {
 	int32_t rc;
-	struct rte_acl_bpf bpx;
 
-	acl_bpf_reset(&bpx);
+	if (ctx->num_tries > 1)
+		printf("%s:%d: !!! WARNING given ACL CTX uses %u tries, "
+			"curret ACL XDP program supports only CTX with "
+			"single trie - BPF matches might be invalid\n",
+			__func__, __LINE__, ctx->num_tries);
 
-	bpx.ctx_fd = bpf_map_get_fd_by_id(bpid->ctx_fd);
-	rc = (bpx.ctx_fd < 0) ? -errno : 0;
-	printf("%s:%d  "
-		"bpf_map_get_fd(=\"%u\") returns %d, errno=%d\n",
-		__func__, __LINE__, bpid->ctx_fd,  bpx.ctx_fd, rc);
 
-	if (rc == 0) {
-		bpx.trans_fd = bpf_map_get_fd_by_id(bpid->trans_fd);
-		rc = (bpx.ctx_fd < 0) ? -errno : 0;
-		printf("%s:%d  "
-			"bpf_map_get_fd(=\"%u\") returns %d, errno=%d\n",
-			__func__, __LINE__, bpid->trans_fd,  bpx.trans_fd, rc);
-	}
-
-	if (rc == 0)
-		rc = fill_ctx_map(&bpx, ctx);
+	rc = fill_ctx_map(bpfd, ctx);
 
 	if (rc == 0)
-		rc = fill_trans_map(&bpx, ctx);
+		rc = fill_trans_map(bpfd, ctx);
 
-	rte_acl_bpf_fini(&bpx);
 	return rc;
 }
 
 void
-rte_acl_bpf_fini(struct rte_acl_bpf *bpx)
+rte_acl_bpf_close(struct rte_acl_bpf_fd *bpx)
 {
 	close(bpx->trans_fd);
 	close(bpx->ctx_fd);
+	close(bpx->rule_fd);
 	acl_bpf_reset(bpx);
 }
 
@@ -328,7 +305,7 @@ acl_trie_search(const struct rte_acl_bpf_ctx *btx, uint32_t trie_idx,
 }
 
 int
-rte_acl_bpf_classify(const struct rte_acl_bpf *bpx, const uint8_t *data,
+rte_acl_bpf_classify(const struct rte_acl_bpf_fd *bpx, const uint8_t *data,
 	uint32_t data_len, uint32_t *res)
 {
 	int32_t rc;
diff --git a/lib/acl/rte_acl.h b/lib/acl/rte_acl.h
index e4a01a9a21..435e10e715 100644
--- a/lib/acl/rte_acl.h
+++ b/lib/acl/rte_acl.h
@@ -363,23 +363,44 @@ rte_acl_list_dump(void);
  * BPF related API
  */
 
-struct rte_acl_bpf {
+struct rte_acl_bpf_fd {
 	/** file desc for transition map */
 	int32_t trans_fd;
 	/** file desc for context map */
 	int32_t ctx_fd;
+	/** file desc for rules map */
+	int32_t rule_fd;
 };
 
+struct rte_acl_bpf_id {
+	/** ACL transitions BPF map ID */
+	uint32_t trans_id;
+	/** ACL context BPF map id */
+	uint32_t ctx_id;
+	/** rules BPF map ID */
+	int32_t rule_id;
+};
+
+/*
+ * Take as input ACL BPF MAP IDs and open corresponding file descriptor for
+ * each of them.
+ */
 int
-rte_acl_bpf_init(struct rte_acl_bpf *bpx, const struct rte_acl_ctx *ctx);
+rte_acl_bpf_open(const struct rte_acl_bpf_id *bpid,
+	struct rte_acl_bpf_fd *bpfd);
 
-int                                                                             rte_acl_bpf_fill(const struct rte_acl_bpf *bpid, const struct rte_acl_ctx *ctx);
+/*
+ * Fill BPF CTX and TRANS MAPs with contents of ACL context.
+ */
+int
+rte_acl_bpf_fill(const struct rte_acl_bpf_fd *bpfd,
+	const struct rte_acl_ctx *ctx);
 
 void
-rte_acl_bpf_fini(struct rte_acl_bpf *bpx);
+rte_acl_bpf_close(struct rte_acl_bpf_fd *bpfd);
 
 int
-rte_acl_bpf_classify(const struct rte_acl_bpf *bpx, const uint8_t *data,
+rte_acl_bpf_classify(const struct rte_acl_bpf_fd *bpfd, const uint8_t *data,
         uint32_t data_len, uint32_t *res);
 
 #ifdef __cplusplus
-- 
2.43.0

